<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>f5e4055def8f483f837130d7a4896207</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="predicting-nba-players-2k-ratings" class="cell markdown" id="HcZkLeAxR-DE">
<h1>Predicting NBA Players 2k Ratings</h1>
</section>
<div class="cell markdown" id="loR_SH55oc1C">
<p><img src="vertopal_50d0c7215e224aa8a1e2703691f9c7da/7d7855de8643670df2093b6d7130b0b8151f7c29.webp" alt="2k23-booker-crop.webp" /></p>
</div>
<section id="table-of-contents" class="cell markdown" id="9q0Tdw87RpFG">
<h1>Table Of Contents</h1>
</section>
<div class="cell markdown" id="MpNlv3KiR01T">
<ol>
<li><p>Introduction/Overview</p></li>
<li><p>Setting Up</p></li>
<li><p>Data Collection, Parsing, and Cleaning</p></li>
<li><p>Data Exploration and Analysis</p>
<ul>
<li>Exploration on Points vs. 2k Rating
<ul>
<li>Linear Regression Analysis</li>
<li>K Nearest Neighbor Analysis</li>
<li>Comparison</li>
</ul></li>
<li>Exploration on Points+Rebounds+Assists vs. 2k Rating
<ul>
<li>Linear Regression Analysis</li>
<li>K Nearest Neighbor Analysis</li>
<li>Comparison</li>
</ul></li>
</ul></li>
<li><p>Conclusion</p></li>
</ol>
</div>
<section id="introductionoverview" class="cell markdown" id="kWWERUfPz0Db">
<h1>Introduction/Overview</h1>
</section>
<div class="cell markdown" id="xqAEyDI8s54g">
<p><img src="vertopal_50d0c7215e224aa8a1e2703691f9c7da/2b05c12a068342a3e849f5e45f3015ce221c798c.webp" alt="6n7rzqsw61g31.webp" /></p>
</div>
<div class="cell markdown" id="6bLceb5Pz3Kz">
<p>NBA: National Basketball Association</p>
<p>NBA 2k is a highly successful sports video game series that animates and virtualizes the world of professional basketball. Take-Two Interactive is the parent organization that is in charge of 2k Sports. 2k Sports is the company that continues to create the game series. NBA 2k is a game series that completely simulates the NBA and WNBA digitally. This means that the game digitizes the characteristics of real players like Lebron James, the courts that you would see the players on like Oracle Arena, the coaches for the teams, the mascots, and all other aspects of the NBA/WNBA viewing experience. You can find pictures of the current virtual players and more information about the game on this site. <a href="https://nba.2k.com/2k23/">Current NBA 2k News</a>. You can also see the picture above for a glimpse into what the game looks like.</p>
<p>NBA 2k works on a new game every year and releases a new version of the game for purchase in September of the next year. For example, 2k23 is released in September of 2022, 2k22 is released in 2021, and so forth (this will be useful when looking at the data). NBA 2k games consist of a plethora of game modes including MyTeam, MyCareer, MyLeague, PlayNow, BlackTop, MyWNBA, and a couple of others. All of these game modes have one thing in common, the overall ratings. The rating for every player is evaluated out of 99. So in other words a 99 overall is the max rating that you a player can get. Every year when a new game is released, NBA 2k also drops a new set of 2k ratings. The 2k ratings correlate with how the player performs that year, fan favorites, and other factors. Due to this, the player ratings might be the same from year to year or they might drastically differ.</p>
<p>To start this tutorial what I wanted to do is to get data about the top 400 rated players in every NBA 2k for the past five years and then obtain the statistics they produced in the season prior to the 2K game being released. With this information, the goal is to test a couple of statistical categories like points, rebounds, and assists to see if they solely affect the rating the player receives. Then I hope to test if the combination of these statistical categories affects the prediction of the rating. The primary goal of this tutorial is to see if we can accurately predict the rating of a player based on the data we received.</p>
</div>
<section id="setting-up" class="cell markdown" id="zEJNK8BJPoZe">
<h1>Setting Up</h1>
</section>
<div class="cell markdown" id="TZOS462GS8HY">
<p>After scouring the internet for an NBA dataset that had all of the stats I wanted in a neat package I found out about nba_api. NBA API provides information about real game stats, player career stats, team stats, and various other NBA-related information. This is a premade API client that accesses NBA.com which holds all the data for the NBA players and presents it to the programmer in a readable and easily accessible manner. The only issue with NBA API was that if I tried to request too much information too fast the request would timeout and the cell would error. Because of this, I had to stray away from this super cool tool. I still left the information just in case you would like to learn more about it for personal use. To learn more about nba_api as a programming tool you can go to <a href="https://github.com/swar/nba_api">NBA API INFO</a></p>
</div>
<div class="cell code" data-execution_count="180" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="mp-rrog4DvPb" data-outputId="30f39717-8d45-4cab-90dd-195524b7e084">
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>pip install nba_api</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: nba_api in /usr/local/lib/python3.8/dist-packages (1.1.14)
Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from nba_api) (2.23.0)
Requirement already satisfied: numpy&lt;2.0.0,&gt;=1.22.2 in /usr/local/lib/python3.8/dist-packages (from nba_api) (1.23.5)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests-&gt;nba_api) (2022.9.24)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests-&gt;nba_api) (1.24.3)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests-&gt;nba_api) (3.0.4)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.8/dist-packages (from requests-&gt;nba_api) (2.10)
</code></pre>
</div>
</div>
<div class="cell markdown" id="9yqiqS0d_iNp">
<p>Unidecode is a project for converting Unicode to ASCII characters. For example, it can turn "ć" into "c". If you want to learn more about what it does and how you can use it go to this link <a href="https://pypi.org/project/Unidecode/">Unidecode Info</a></p>
</div>
<div class="cell code" data-execution_count="181" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="Vdxwh_8RcfUv" data-outputId="bb564ba8-9f6d-4e86-cf3a-4998f5ec1065">
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>pip install Unidecode</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: Unidecode in /usr/local/lib/python3.8/dist-packages (1.3.6)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="182" id="ziil1amVh37P">
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import all of the neccessary tools</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> pearsonr</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sqlite3 <span class="im">as</span> sqlite_file</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> linear_model</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.formula.api <span class="im">import</span> ols</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> unidecode <span class="im">import</span> unidecode</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> neighbors</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">&#39;display.max_columns&#39;</span>, <span class="va">None</span>)</span></code></pre></div>
</div>
<section id="data-collection-parsing-and-cleaning" class="cell markdown" id="O6Ndgn3j1RSX">
<h1>Data collection, Parsing, and Cleaning</h1>
</section>
<div class="cell markdown" id="93terTbZ66JV">
<p>I got the data for the 2k ratings of the top 400 ratings throughout the 5 years. For reference NBA 2K23 rating or the 2022-23 season refers to the rating the player received for the year 2022. I got all of the 2K ratings on <a href="https://hoopshype.com/nba2k/">hoopshype</a>. The data was well organized and easy to parse so it was the ideal site with the right information I needed. The function I created takes in three arguments the link for the request, the season that the rating was for, and the exact year the rating was for. A season in basketball refers to the year they played. For example, if they started to play for the year in October of 2022 then the season would be 2022-23. Since the data’s structure on the site did not differ from year to year, the parsing method stayed the same each time with only the request being different.</p>
<p>I combined all of the data from all of the years into one big data frame because the names of the players and years should not affect their ratings in our model. The stats they put up during the season should play heavily into the rating they get from 2K Sports.</p>
</div>
<div class="cell code" data-execution_count="183" data-colab="{&quot;height&quot;:520,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="MZVpKhkJxuL3" data-outputId="6f7366fd-4bb6-4a56-a6bc-d5ff79cad14b">
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rating_grabber(link, year, exact):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Request link</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  rating <span class="op">=</span> requests.get(link)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Use bsoup to parse the html</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  rating_soup <span class="op">=</span> BeautifulSoup(rating.content, <span class="st">&#39;html.parser&#39;</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  elements <span class="op">=</span> rating_soup.find_all(<span class="st">&#39;tr&#39;</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># set columns for dictionary</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  rating_dictionary <span class="op">=</span> { <span class="st">&quot;Rank&quot;</span> : [], <span class="st">&quot;Name&quot;</span> : [], <span class="st">&quot;Rating&quot;</span> : []}</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># read data on site and place specific data in dictionary</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">401</span>):</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># All the data in the HTML is separated by a new line and a tab so this process removes both during the appending process.</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>      rating_dictionary[<span class="st">&quot;Rank&quot;</span>].append(<span class="bu">int</span>(elements[i].findChildren(<span class="st">&quot;td&quot;</span>)[<span class="dv">0</span>].get_text().replace(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>, <span class="st">&#39;&#39;</span>).replace(<span class="st">&#39;</span><span class="ch">\t</span><span class="st">&#39;</span>, <span class="st">&#39;&#39;</span>)))</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>      rating_dictionary[<span class="st">&quot;Name&quot;</span>].append(elements[i].findChildren(<span class="st">&quot;td&quot;</span>)[<span class="dv">1</span>].get_text().replace(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>, <span class="st">&#39;&#39;</span>).replace(<span class="st">&#39;</span><span class="ch">\t</span><span class="st">&#39;</span>, <span class="st">&#39;&#39;</span>))</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>      rating_dictionary[<span class="st">&quot;Rating&quot;</span>].append(<span class="bu">int</span>(elements[i].findChildren(<span class="st">&quot;td&quot;</span>)[<span class="dv">2</span>].get_text().replace(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>, <span class="st">&#39;&#39;</span>).replace(<span class="st">&#39;</span><span class="ch">\t</span><span class="st">&#39;</span>, <span class="st">&#39;&#39;</span>)))</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>  rating_df <span class="op">=</span> pd.DataFrame.from_dict(rating_dictionary)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>  rating_df[<span class="st">&#39;year&#39;</span>] <span class="op">=</span> year</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>  rating_df[<span class="st">&#39;exact&#39;</span>] <span class="op">=</span> exact</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> rating_df</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Get data for all 5 years using rating_grabber scraping function</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>ratings_23 <span class="op">=</span> rating_grabber(<span class="st">&quot;https://hoopshype.com/nba2k/&quot;</span>,           <span class="st">&quot;2021-22&quot;</span>, <span class="dv">2022</span>)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>ratings_22 <span class="op">=</span> rating_grabber(<span class="st">&quot;https://hoopshype.com/nba2k/2021-2022/&quot;</span>, <span class="st">&quot;2020-21&quot;</span>, <span class="dv">2021</span>)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>ratings_21 <span class="op">=</span> rating_grabber(<span class="st">&quot;https://hoopshype.com/nba2k/2020-2021/&quot;</span>, <span class="st">&quot;2019-20&quot;</span>, <span class="dv">2020</span>)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>ratings_20 <span class="op">=</span> rating_grabber(<span class="st">&quot;https://hoopshype.com/nba2k/2019-2020/&quot;</span>, <span class="st">&quot;2018-19&quot;</span>, <span class="dv">2019</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>ratings_19 <span class="op">=</span> rating_grabber(<span class="st">&quot;https://hoopshype.com/nba2k/2018-2019/&quot;</span>, <span class="st">&quot;2017-18&quot;</span>, <span class="dv">2018</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Add all of the ratings into one big dataframe</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>ratings <span class="op">=</span> ratings_23.append([ratings_22, ratings_21, ratings_20, ratings_19], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>ratings.head(<span class="dv">15</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="183">

  <div id="df-1353e6fb-51dc-47bb-bfe6-fdbce3504713">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Rank</th>
      <th>Name</th>
      <th>Rating</th>
      <th>year</th>
      <th>exact</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Giannis Antetokounmpo</td>
      <td>97</td>
      <td>2021-22</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Joel Embiid</td>
      <td>96</td>
      <td>2021-22</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>LeBron James</td>
      <td>96</td>
      <td>2021-22</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>Kevin Durant</td>
      <td>96</td>
      <td>2021-22</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>Nikola Jokic</td>
      <td>96</td>
      <td>2021-22</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2</td>
      <td>Stephen Curry</td>
      <td>96</td>
      <td>2021-22</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>Luka Doncic</td>
      <td>95</td>
      <td>2021-22</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>Kawhi Leonard</td>
      <td>94</td>
      <td>2021-22</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9</td>
      <td>Jayson Tatum</td>
      <td>93</td>
      <td>2021-22</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>9</th>
      <td>9</td>
      <td>Ja Morant</td>
      <td>93</td>
      <td>2021-22</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>10</th>
      <td>9</td>
      <td>Jimmy Butler</td>
      <td>93</td>
      <td>2021-22</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>11</th>
      <td>12</td>
      <td>Devin Booker</td>
      <td>91</td>
      <td>2021-22</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>12</th>
      <td>13</td>
      <td>Trae Young</td>
      <td>90</td>
      <td>2021-22</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>13</th>
      <td>13</td>
      <td>Anthony Davis</td>
      <td>90</td>
      <td>2021-22</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>14</th>
      <td>13</td>
      <td>Chris Paul</td>
      <td>90</td>
      <td>2021-22</td>
      <td>2022</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-1353e6fb-51dc-47bb-bfe6-fdbce3504713')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-1353e6fb-51dc-47bb-bfe6-fdbce3504713 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-1353e6fb-51dc-47bb-bfe6-fdbce3504713');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell markdown" id="P12jXwHRBmXp">
<p>I plotted the 2k ratings in two ways, a scatter plot and a violin plot. The scatter plot was not ideal for analyzing the data because it made it seem as if there were only a couple of points per year when there are 400. To make it a lot easier to see the way the data is laid out I used a violin plot. The violin plot is the perfect way to see how the data is spread out and where most of the data resides.</p>
</div>
<div class="cell code" data-execution_count="184" data-colab="{&quot;height&quot;:639,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="cM3idp6DA1Yh" data-outputId="25119077-4d64-459b-f280-922c834a2bf3">
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot all of the points as a scatter plot</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>fig, plot <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>plot.set_title(<span class="st">&#39;2K Rating Distribution Over Time&#39;</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>plot.set_xlabel(<span class="st">&quot;Season&quot;</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>plot.set_ylabel(<span class="st">&quot;2K Rating&quot;</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>plot.scatter(ratings[<span class="st">&#39;year&#39;</span>], ratings[<span class="st">&#39;Rating&#39;</span>], color <span class="op">=</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="184">
<pre><code>&lt;matplotlib.collections.PathCollection at 0x7fd4b170e880&gt;</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_50d0c7215e224aa8a1e2703691f9c7da/cb80f7c8ef6b434ce2b6de860a2b0ce80b22fad5.png" /></p>
</div>
</div>
<div class="cell markdown" id="teEu6eyFFAI7">
<p>The distribution of 2k ratings from year to year seems to stay consistent. 2K sports likes to have a large number of players at 75 and only the best of the best above 90 overall so this distribution makes sense. All of the distributions are unimodal (with a peak around the 75 Rating mark) and skewed upward. Since the distributions are similar from year to year we can also conclude how 2k Sports calculates these ratings should also be similar or even the same from year to year.</p>
</div>
<div class="cell code" data-execution_count="185" data-colab="{&quot;height&quot;:295,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="PcJeswniEFKn" data-outputId="cbcc7dc1-d1ac-42c0-f9e0-10a411c55942">
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>v_plot <span class="op">=</span> sns.violinplot(data <span class="op">=</span> ratings, x<span class="op">=</span><span class="st">&quot;year&quot;</span>, y<span class="op">=</span><span class="st">&quot;Rating&quot;</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>v_plot.set_title(<span class="st">&#39;2K Rating Distribution Over Time&#39;</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>v_plot.set_xlabel(<span class="st">&quot;Season&quot;</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>v_plot.set_ylabel(<span class="st">&quot;2K Rating&quot;</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>v_plot.invert_xaxis()</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the distribution of the data as a violin plot</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># x-axis for the plot is the season years and y-axis is the 2k Ratings</span></span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_50d0c7215e224aa8a1e2703691f9c7da/17923f62db2baedb4a9e38e1208dbff52e857298.png" /></p>
</div>
</div>
<div class="cell markdown" id="xJdox9X2jp3t">
<p>Many of the names that were on HoopsHype.com were not formatted such that they would be the same as some of the datasets I found. For example, a whole bunch of datasets incorporated accent marks in names, and some names had abbreviations without the "." in between the letters of the abbreviated name. To help fix this issue I replaced abbreviated names like RJ, CJ, and other names of that nature with R.J. because that was the style that the NBA player CSV had in its system.</p>
</div>
<div class="cell code" data-execution_count="186" id="IJ8in-8PdTAu">
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get any names that had 2 capital letters back to back</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># add &quot;.&quot; in between code</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> index, row <span class="kw">in</span> ratings.iterrows():</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (re.search(<span class="st">&quot;[A-Z][A-Z]&quot;</span>, row.Name) <span class="op">!=</span> <span class="va">None</span>) <span class="op">&amp;</span> ((row.Name <span class="op">!=</span> <span class="st">&quot;Glenn Robinson&quot;</span>) <span class="op">|</span> (row.Name <span class="op">!=</span> <span class="st">&quot;Gary Payton&quot;</span>) <span class="op">|</span> (row.Name <span class="op">!=</span> <span class="st">&quot;OG Anunoby&quot;</span>)):</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    name <span class="op">=</span> row[<span class="st">&quot;Name&quot;</span>].split(<span class="st">&quot; &quot;</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># split the names and add a &quot;.&quot; in between the 2 letters to match up with the format of the csv file</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    name[<span class="dv">0</span>] <span class="op">=</span> name[<span class="dv">0</span>].replace(<span class="st">&#39;&#39;</span>, <span class="st">&#39;.&#39;</span>).replace(<span class="st">&#39;.&#39;</span>, <span class="st">&#39;&#39;</span>, <span class="dv">1</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># switch out names</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    ratings[<span class="st">&quot;Name&quot;</span>][index] <span class="op">=</span> name[<span class="dv">0</span>] <span class="op">+</span> <span class="st">&quot; &quot;</span> <span class="op">+</span> name[<span class="dv">1</span>]</span></code></pre></div>
</div>
<div class="cell markdown" id="DSEohKlmDp9Q">
<p>The NBA API tool was the tool that I wanted to utilize but the tool would timeout if I accessed it more than 10 times. Since I have around 2000 elements that would not be a viable option so I decided to switch up my approach. I found a CSV online with almost the same stats. The data set I am using can be found at <a href="https://data.world/etocco/nba-player-stats">Dataset</a>. The cleaning that is done is converting the letters with all of the accent marks to regular English letters. For example, the unidecode function would change ć to c.</p>
</div>
<div class="cell code" data-execution_count="187" data-colab="{&quot;height&quot;:844,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="1J4sViGvDqB5" data-outputId="64a31b78-3907-49c9-e01c-1d865a46c622">
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>players_stats <span class="op">=</span> pd.read_csv(<span class="st">&quot;NBA_Player_Stats_2.csv&quot;</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># get only data for past 5 years</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>players_stats <span class="op">=</span> players_stats[(players_stats.Season <span class="op">==</span> <span class="st">&quot;2021-22&quot;</span>) <span class="op">|</span> (players_stats.Season <span class="op">==</span> <span class="st">&quot;2020-21&quot;</span>) <span class="op">|</span> (players_stats.Season <span class="op">==</span> <span class="st">&quot;2019-20&quot;</span>)<span class="op">|</span> (players_stats.Season <span class="op">==</span> <span class="st">&quot;2018-19&quot;</span>) <span class="op">|</span> (players_stats.Season <span class="op">==</span> <span class="st">&quot;2017-18&quot;</span>)].reset_index().drop(<span class="st">&quot;index&quot;</span>, axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># change column name for merging process</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>players_stats <span class="op">=</span> players_stats.rename(columns <span class="op">=</span>{ <span class="st">&quot;Player&quot;</span> : <span class="st">&quot;Name&quot;</span> , <span class="st">&quot;Season&quot;</span> : <span class="st">&quot;year&quot;</span>})</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co"># convert all unicode characters within the data set into ASCII characters so that the data is a lot more readable</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>players_stats[<span class="st">&quot;Name&quot;</span>] <span class="op">=</span>  players_stats[<span class="st">&#39;Name&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: unidecode(x))</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>players_stats.head(<span class="dv">15</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="187">

  <div id="df-e35ae245-7724-4e1b-8bc6-f854c86baa2b">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Rk</th>
      <th>Name</th>
      <th>Pos</th>
      <th>Age</th>
      <th>Tm</th>
      <th>G</th>
      <th>GS</th>
      <th>MP</th>
      <th>FG</th>
      <th>FGA</th>
      <th>FG%</th>
      <th>3P</th>
      <th>3PA</th>
      <th>3P%</th>
      <th>2P</th>
      <th>2PA</th>
      <th>2P%</th>
      <th>eFG%</th>
      <th>FT</th>
      <th>FTA</th>
      <th>FT%</th>
      <th>ORB</th>
      <th>DRB</th>
      <th>TRB</th>
      <th>AST</th>
      <th>STL</th>
      <th>BLK</th>
      <th>TOV</th>
      <th>PF</th>
      <th>PTS</th>
      <th>year</th>
      <th>MVP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Alex Abrines</td>
      <td>SG</td>
      <td>24</td>
      <td>OKC</td>
      <td>75</td>
      <td>8</td>
      <td>15.1</td>
      <td>1.5</td>
      <td>3.9</td>
      <td>0.395</td>
      <td>1.1</td>
      <td>2.9</td>
      <td>0.380</td>
      <td>0.4</td>
      <td>0.9</td>
      <td>0.443</td>
      <td>0.540</td>
      <td>0.5</td>
      <td>0.6</td>
      <td>0.848</td>
      <td>0.3</td>
      <td>1.2</td>
      <td>1.5</td>
      <td>0.4</td>
      <td>0.5</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>1.7</td>
      <td>4.7</td>
      <td>2017-18</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Quincy Acy</td>
      <td>PF</td>
      <td>27</td>
      <td>BRK</td>
      <td>70</td>
      <td>8</td>
      <td>19.4</td>
      <td>1.9</td>
      <td>5.2</td>
      <td>0.356</td>
      <td>1.5</td>
      <td>4.2</td>
      <td>0.349</td>
      <td>0.4</td>
      <td>1.0</td>
      <td>0.384</td>
      <td>0.496</td>
      <td>0.7</td>
      <td>0.9</td>
      <td>0.817</td>
      <td>0.6</td>
      <td>3.1</td>
      <td>3.7</td>
      <td>0.8</td>
      <td>0.5</td>
      <td>0.4</td>
      <td>0.9</td>
      <td>2.1</td>
      <td>5.9</td>
      <td>2017-18</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Steven Adams</td>
      <td>C</td>
      <td>24</td>
      <td>OKC</td>
      <td>76</td>
      <td>76</td>
      <td>32.7</td>
      <td>5.9</td>
      <td>9.4</td>
      <td>0.629</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000</td>
      <td>5.9</td>
      <td>9.3</td>
      <td>0.631</td>
      <td>0.629</td>
      <td>2.1</td>
      <td>3.8</td>
      <td>0.559</td>
      <td>5.1</td>
      <td>4.0</td>
      <td>9.0</td>
      <td>1.2</td>
      <td>1.2</td>
      <td>1.0</td>
      <td>1.7</td>
      <td>2.8</td>
      <td>13.9</td>
      <td>2017-18</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Bam Adebayo</td>
      <td>C</td>
      <td>20</td>
      <td>MIA</td>
      <td>69</td>
      <td>19</td>
      <td>19.8</td>
      <td>2.5</td>
      <td>4.9</td>
      <td>0.512</td>
      <td>0.0</td>
      <td>0.1</td>
      <td>0.000</td>
      <td>2.5</td>
      <td>4.8</td>
      <td>0.523</td>
      <td>0.512</td>
      <td>1.9</td>
      <td>2.6</td>
      <td>0.721</td>
      <td>1.7</td>
      <td>3.8</td>
      <td>5.5</td>
      <td>1.5</td>
      <td>0.5</td>
      <td>0.6</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>6.9</td>
      <td>2017-18</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Arron Afflalo</td>
      <td>SG</td>
      <td>32</td>
      <td>ORL</td>
      <td>53</td>
      <td>3</td>
      <td>12.9</td>
      <td>1.2</td>
      <td>3.1</td>
      <td>0.401</td>
      <td>0.5</td>
      <td>1.3</td>
      <td>0.386</td>
      <td>0.7</td>
      <td>1.7</td>
      <td>0.413</td>
      <td>0.485</td>
      <td>0.4</td>
      <td>0.5</td>
      <td>0.846</td>
      <td>0.1</td>
      <td>1.2</td>
      <td>1.2</td>
      <td>0.6</td>
      <td>0.1</td>
      <td>0.2</td>
      <td>0.4</td>
      <td>1.1</td>
      <td>3.4</td>
      <td>2017-18</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>Cole Aldrich</td>
      <td>C</td>
      <td>29</td>
      <td>MIN</td>
      <td>21</td>
      <td>0</td>
      <td>2.3</td>
      <td>0.2</td>
      <td>0.7</td>
      <td>0.333</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.2</td>
      <td>0.7</td>
      <td>0.333</td>
      <td>0.333</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>0.333</td>
      <td>0.1</td>
      <td>0.6</td>
      <td>0.7</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.5</td>
      <td>0.6</td>
      <td>2017-18</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>LaMarcus Aldridge</td>
      <td>C</td>
      <td>32</td>
      <td>SAS</td>
      <td>75</td>
      <td>75</td>
      <td>33.5</td>
      <td>9.2</td>
      <td>18.0</td>
      <td>0.510</td>
      <td>0.4</td>
      <td>1.2</td>
      <td>0.293</td>
      <td>8.8</td>
      <td>16.7</td>
      <td>0.526</td>
      <td>0.520</td>
      <td>4.5</td>
      <td>5.3</td>
      <td>0.837</td>
      <td>3.3</td>
      <td>5.2</td>
      <td>8.5</td>
      <td>2.0</td>
      <td>0.6</td>
      <td>1.2</td>
      <td>1.5</td>
      <td>2.1</td>
      <td>23.1</td>
      <td>2017-18</td>
      <td>False</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>Jarrett Allen</td>
      <td>C</td>
      <td>19</td>
      <td>BRK</td>
      <td>72</td>
      <td>31</td>
      <td>20.0</td>
      <td>3.3</td>
      <td>5.5</td>
      <td>0.589</td>
      <td>0.1</td>
      <td>0.2</td>
      <td>0.333</td>
      <td>3.2</td>
      <td>5.3</td>
      <td>0.599</td>
      <td>0.596</td>
      <td>1.6</td>
      <td>2.0</td>
      <td>0.776</td>
      <td>2.0</td>
      <td>3.4</td>
      <td>5.4</td>
      <td>0.7</td>
      <td>0.4</td>
      <td>1.2</td>
      <td>1.1</td>
      <td>2.0</td>
      <td>8.2</td>
      <td>2017-18</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9</td>
      <td>Kadeem Allen</td>
      <td>PG</td>
      <td>25</td>
      <td>BOS</td>
      <td>18</td>
      <td>1</td>
      <td>5.9</td>
      <td>0.3</td>
      <td>1.2</td>
      <td>0.273</td>
      <td>0.0</td>
      <td>0.6</td>
      <td>0.000</td>
      <td>0.3</td>
      <td>0.6</td>
      <td>0.545</td>
      <td>0.273</td>
      <td>0.4</td>
      <td>0.5</td>
      <td>0.778</td>
      <td>0.2</td>
      <td>0.4</td>
      <td>0.6</td>
      <td>0.7</td>
      <td>0.2</td>
      <td>0.1</td>
      <td>0.5</td>
      <td>0.8</td>
      <td>1.1</td>
      <td>2017-18</td>
      <td>False</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10</td>
      <td>Tony Allen</td>
      <td>SF</td>
      <td>36</td>
      <td>NOP</td>
      <td>22</td>
      <td>0</td>
      <td>12.4</td>
      <td>2.0</td>
      <td>4.1</td>
      <td>0.484</td>
      <td>0.2</td>
      <td>0.5</td>
      <td>0.333</td>
      <td>1.8</td>
      <td>3.6</td>
      <td>0.506</td>
      <td>0.505</td>
      <td>0.5</td>
      <td>1.0</td>
      <td>0.524</td>
      <td>0.9</td>
      <td>1.2</td>
      <td>2.1</td>
      <td>0.4</td>
      <td>0.5</td>
      <td>0.1</td>
      <td>0.9</td>
      <td>2.2</td>
      <td>4.7</td>
      <td>2017-18</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10</th>
      <td>11</td>
      <td>Al-Farouq Aminu</td>
      <td>PF</td>
      <td>27</td>
      <td>POR</td>
      <td>69</td>
      <td>67</td>
      <td>30.0</td>
      <td>3.3</td>
      <td>8.4</td>
      <td>0.395</td>
      <td>1.8</td>
      <td>4.9</td>
      <td>0.369</td>
      <td>1.5</td>
      <td>3.5</td>
      <td>0.432</td>
      <td>0.503</td>
      <td>0.9</td>
      <td>1.2</td>
      <td>0.738</td>
      <td>1.4</td>
      <td>6.2</td>
      <td>7.6</td>
      <td>1.2</td>
      <td>1.1</td>
      <td>0.6</td>
      <td>1.1</td>
      <td>2.0</td>
      <td>9.3</td>
      <td>2017-18</td>
      <td>False</td>
    </tr>
    <tr>
      <th>11</th>
      <td>12</td>
      <td>Justin Anderson</td>
      <td>SF</td>
      <td>24</td>
      <td>PHI</td>
      <td>38</td>
      <td>0</td>
      <td>13.7</td>
      <td>2.3</td>
      <td>5.3</td>
      <td>0.431</td>
      <td>0.9</td>
      <td>2.7</td>
      <td>0.330</td>
      <td>1.4</td>
      <td>2.6</td>
      <td>0.535</td>
      <td>0.515</td>
      <td>0.7</td>
      <td>1.0</td>
      <td>0.737</td>
      <td>0.7</td>
      <td>1.8</td>
      <td>2.4</td>
      <td>0.7</td>
      <td>0.4</td>
      <td>0.2</td>
      <td>0.4</td>
      <td>1.4</td>
      <td>6.2</td>
      <td>2017-18</td>
      <td>False</td>
    </tr>
    <tr>
      <th>12</th>
      <td>13</td>
      <td>Kyle Anderson</td>
      <td>SF</td>
      <td>24</td>
      <td>SAS</td>
      <td>74</td>
      <td>67</td>
      <td>26.7</td>
      <td>3.1</td>
      <td>5.9</td>
      <td>0.527</td>
      <td>0.3</td>
      <td>0.8</td>
      <td>0.333</td>
      <td>2.9</td>
      <td>5.1</td>
      <td>0.556</td>
      <td>0.549</td>
      <td>1.4</td>
      <td>2.0</td>
      <td>0.712</td>
      <td>1.1</td>
      <td>4.2</td>
      <td>5.4</td>
      <td>2.7</td>
      <td>1.6</td>
      <td>0.8</td>
      <td>1.3</td>
      <td>1.5</td>
      <td>7.9</td>
      <td>2017-18</td>
      <td>False</td>
    </tr>
    <tr>
      <th>13</th>
      <td>14</td>
      <td>Ryan Anderson</td>
      <td>PF</td>
      <td>29</td>
      <td>HOU</td>
      <td>66</td>
      <td>50</td>
      <td>26.1</td>
      <td>3.1</td>
      <td>7.3</td>
      <td>0.431</td>
      <td>2.0</td>
      <td>5.1</td>
      <td>0.386</td>
      <td>1.2</td>
      <td>2.1</td>
      <td>0.539</td>
      <td>0.568</td>
      <td>1.1</td>
      <td>1.4</td>
      <td>0.774</td>
      <td>1.4</td>
      <td>3.6</td>
      <td>5.0</td>
      <td>0.9</td>
      <td>0.4</td>
      <td>0.3</td>
      <td>0.6</td>
      <td>1.9</td>
      <td>9.3</td>
      <td>2017-18</td>
      <td>False</td>
    </tr>
    <tr>
      <th>14</th>
      <td>15</td>
      <td>Ike Anigbogu</td>
      <td>C</td>
      <td>19</td>
      <td>IND</td>
      <td>11</td>
      <td>0</td>
      <td>2.7</td>
      <td>0.4</td>
      <td>0.8</td>
      <td>0.444</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.4</td>
      <td>0.8</td>
      <td>0.444</td>
      <td>0.444</td>
      <td>0.5</td>
      <td>0.5</td>
      <td>0.833</td>
      <td>0.5</td>
      <td>0.4</td>
      <td>0.8</td>
      <td>0.0</td>
      <td>0.1</td>
      <td>0.3</td>
      <td>0.2</td>
      <td>0.1</td>
      <td>1.2</td>
      <td>2017-18</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-e35ae245-7724-4e1b-8bc6-f854c86baa2b')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-e35ae245-7724-4e1b-8bc6-f854c86baa2b button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-e35ae245-7724-4e1b-8bc6-f854c86baa2b');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell markdown" id="Zu0906hXG_8T">
<p>To preface all of this I would like to explain a couple of terms, points are when the player puts the ball into the hoop, rebounds are when a player gets the ball after a missed attempt at the hoop, and an assist is when a player gives the ball to a teammate and they score right after. Also, all of these stats are per game so for the whole year, they averaged these stats. For example, Alex Abrines averaged 4.7 points per game in 2017. The distribution of the stats seems to follow the same distribution pattern as the 2k ratings. We can see that a lot of players average around the 10-stat mark but as you go up you barely any people putting up those types of statistics. This would make sense when compared to the NBA ratings because only those very few players that are putting up major stats should receive the highest ratings.</p>
</div>
<div class="cell code" data-execution_count="188" data-colab="{&quot;height&quot;:313,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="NIDMHrE0dpB6" data-outputId="7c9c5097-28fc-4186-fabe-ccbcbce97da9">
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make column for points + rebounds + assists </span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>players_stats[<span class="st">&#39;stats_important&#39;</span>] <span class="op">=</span> players_stats.AST <span class="op">+</span> players_stats.PTS <span class="op">+</span> players_stats.ORB <span class="op">+</span> players_stats.DRB</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the data</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>stats_plot <span class="op">=</span> sns.violinplot(data <span class="op">=</span> players_stats, x<span class="op">=</span><span class="st">&quot;year&quot;</span>, y<span class="op">=</span><span class="st">&quot;stats_important&quot;</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>stats_plot.set_title(<span class="st">&#39;Pts+Reb+Ast Distribution Over Time&#39;</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>stats_plot.set_xlabel(<span class="st">&quot;Season&quot;</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>stats_plot.set_ylabel(<span class="st">&quot;Pts+Reb+Ast&quot;</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the distribution of the data as a violin plot</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co"># x-axis for the plot is time in years and y-axis is the Points + Rebounds + Assists </span></span></code></pre></div>
<div class="output execute_result" data-execution_count="188">
<pre><code>Text(0, 0.5, &#39;Pts+Reb+Ast&#39;)</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_50d0c7215e224aa8a1e2703691f9c7da/39a64e08a2fbc35fe6e0f9e1aff5ecc7d26797c8.png" /></p>
</div>
</div>
<div class="cell markdown" id="aGU9dk70LVvi">
<p>Some players occur multiple times in the CSV for the same year. This usually means they switched teams a mid year and so their stats for that team is marked as a different row. To combat this multiple identical values for name and year, I grouped the values based on name and year then took the average. I then merged this new data frame with all the multiple values grouped and averaged with the data frame with all of the 2k ratings. This is to assign the statistics we have for the players with their adjacent 2k rating.</p>
<p>After merging the two data frames so that the 2kratings would be paired up with the NBA players and their stats I saw that a couple of players had ratings but no stats for that year. After further research and personal experience, I realized that 2k Sports would rate players who just got drafted into the league so they have 0 games played and some players who had injuries that forced them to sit out for the year. These injuries made up a small number of players without stats so a lot of the NaN data was made up of players who were just drafted. Since in both cases it would be difficult to fill in stats that made sense in the situation it was best to just drop the values altogether. So we then drop all of the rows that have NaN as their values in the points, rebounds, assists, games played, or 2k ratings because these are crucial when fitting the regression models in the following analysis.</p>
</div>
<div class="cell code" data-execution_count="189" data-colab="{&quot;height&quot;:844,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="m0yf-pmHhnre" data-outputId="c2ceda3d-0841-47c1-8b3d-f623e02448e0">
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>newdf1 <span class="op">=</span> players_stats.groupby([<span class="st">&#39;Name&#39;</span>, <span class="st">&#39;year&#39;</span>]).mean()</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># players_stats = players_stats.drop_duplicates(subset=[&#39;Name&#39;, &#39;year&#39;], keep=&#39;first&#39;)</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> pd.merge(newdf1, ratings, on <span class="op">=</span> [<span class="st">&quot;Name&quot;</span>, <span class="st">&quot;year&quot;</span>], how <span class="op">=</span> <span class="st">&quot;right&quot;</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> test[(test.PTS.notnull()) <span class="op">&amp;</span> (test.AST.notnull()) <span class="op">&amp;</span> (test.ORB.notnull()) <span class="op">&amp;</span> (test.DRB.notnull()) <span class="op">&amp;</span> (test.G.notnull()) <span class="op">&amp;</span> (test.STL.notnull()) <span class="op">&amp;</span> (test.BLK.notnull()) <span class="op">&amp;</span> (test[<span class="st">&#39;Rating&#39;</span>].notnull())]</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>test.head(<span class="dv">15</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="189">

  <div id="df-a9f8c235-9b69-4fd8-9222-a7612f0206c1">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>year</th>
      <th>Rk</th>
      <th>Age</th>
      <th>G</th>
      <th>GS</th>
      <th>MP</th>
      <th>FG</th>
      <th>FGA</th>
      <th>FG%</th>
      <th>3P</th>
      <th>3PA</th>
      <th>3P%</th>
      <th>2P</th>
      <th>2PA</th>
      <th>2P%</th>
      <th>eFG%</th>
      <th>FT</th>
      <th>FTA</th>
      <th>FT%</th>
      <th>ORB</th>
      <th>DRB</th>
      <th>TRB</th>
      <th>AST</th>
      <th>STL</th>
      <th>BLK</th>
      <th>TOV</th>
      <th>PF</th>
      <th>PTS</th>
      <th>MVP</th>
      <th>stats_important</th>
      <th>Rank</th>
      <th>Rating</th>
      <th>exact</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Giannis Antetokounmpo</td>
      <td>2021-22</td>
      <td>12.0</td>
      <td>27.0</td>
      <td>67.000000</td>
      <td>67.000000</td>
      <td>32.9</td>
      <td>10.300000</td>
      <td>18.600000</td>
      <td>0.553000</td>
      <td>1.100000</td>
      <td>3.600000</td>
      <td>0.293000</td>
      <td>9.200000</td>
      <td>15.000000</td>
      <td>0.616</td>
      <td>0.582000</td>
      <td>8.300000</td>
      <td>11.400000</td>
      <td>0.722000</td>
      <td>2.0</td>
      <td>9.600000</td>
      <td>11.6</td>
      <td>5.800000</td>
      <td>1.100000</td>
      <td>1.4</td>
      <td>3.3</td>
      <td>3.200000</td>
      <td>29.900000</td>
      <td>0.0</td>
      <td>47.300000</td>
      <td>1</td>
      <td>97</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Joel Embiid</td>
      <td>2021-22</td>
      <td>162.0</td>
      <td>27.0</td>
      <td>68.000000</td>
      <td>68.000000</td>
      <td>33.8</td>
      <td>9.800000</td>
      <td>19.600000</td>
      <td>0.499000</td>
      <td>1.400000</td>
      <td>3.700000</td>
      <td>0.371000</td>
      <td>8.400000</td>
      <td>15.900000</td>
      <td>0.529</td>
      <td>0.534000</td>
      <td>9.600000</td>
      <td>11.800000</td>
      <td>0.814000</td>
      <td>2.1</td>
      <td>9.600000</td>
      <td>11.7</td>
      <td>4.200000</td>
      <td>1.100000</td>
      <td>1.5</td>
      <td>3.1</td>
      <td>2.700000</td>
      <td>30.600000</td>
      <td>0.0</td>
      <td>46.500000</td>
      <td>2</td>
      <td>96</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>2</th>
      <td>LeBron James</td>
      <td>2021-22</td>
      <td>274.0</td>
      <td>37.0</td>
      <td>56.000000</td>
      <td>56.000000</td>
      <td>37.2</td>
      <td>11.400000</td>
      <td>21.800000</td>
      <td>0.524000</td>
      <td>2.900000</td>
      <td>8.000000</td>
      <td>0.359000</td>
      <td>8.600000</td>
      <td>13.800000</td>
      <td>0.620</td>
      <td>0.590000</td>
      <td>4.500000</td>
      <td>6.000000</td>
      <td>0.756000</td>
      <td>1.1</td>
      <td>7.100000</td>
      <td>8.2</td>
      <td>6.200000</td>
      <td>1.300000</td>
      <td>1.1</td>
      <td>3.5</td>
      <td>2.200000</td>
      <td>30.300000</td>
      <td>0.0</td>
      <td>44.700000</td>
      <td>2</td>
      <td>96</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Kevin Durant</td>
      <td>2021-22</td>
      <td>154.0</td>
      <td>33.0</td>
      <td>55.000000</td>
      <td>55.000000</td>
      <td>37.2</td>
      <td>10.500000</td>
      <td>20.300000</td>
      <td>0.518000</td>
      <td>2.100000</td>
      <td>5.500000</td>
      <td>0.383000</td>
      <td>8.400000</td>
      <td>14.800000</td>
      <td>0.568</td>
      <td>0.570000</td>
      <td>6.800000</td>
      <td>7.400000</td>
      <td>0.910000</td>
      <td>0.5</td>
      <td>6.900000</td>
      <td>7.4</td>
      <td>6.400000</td>
      <td>0.900000</td>
      <td>0.9</td>
      <td>3.5</td>
      <td>2.100000</td>
      <td>29.900000</td>
      <td>0.0</td>
      <td>43.700000</td>
      <td>2</td>
      <td>96</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Nikola Jokic</td>
      <td>2021-22</td>
      <td>290.0</td>
      <td>26.0</td>
      <td>74.000000</td>
      <td>74.000000</td>
      <td>33.5</td>
      <td>10.300000</td>
      <td>17.700000</td>
      <td>0.583000</td>
      <td>1.300000</td>
      <td>3.900000</td>
      <td>0.337000</td>
      <td>9.000000</td>
      <td>13.800000</td>
      <td>0.652</td>
      <td>0.620000</td>
      <td>5.100000</td>
      <td>6.300000</td>
      <td>0.810000</td>
      <td>2.8</td>
      <td>11.000000</td>
      <td>13.8</td>
      <td>7.900000</td>
      <td>1.500000</td>
      <td>0.9</td>
      <td>3.8</td>
      <td>2.600000</td>
      <td>27.100000</td>
      <td>1.0</td>
      <td>48.800000</td>
      <td>2</td>
      <td>96</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Stephen Curry</td>
      <td>2021-22</td>
      <td>126.0</td>
      <td>33.0</td>
      <td>64.000000</td>
      <td>64.000000</td>
      <td>34.5</td>
      <td>8.400000</td>
      <td>19.100000</td>
      <td>0.437000</td>
      <td>4.500000</td>
      <td>11.700000</td>
      <td>0.380000</td>
      <td>3.900000</td>
      <td>7.400000</td>
      <td>0.527</td>
      <td>0.554000</td>
      <td>4.300000</td>
      <td>4.700000</td>
      <td>0.923000</td>
      <td>0.5</td>
      <td>4.700000</td>
      <td>5.2</td>
      <td>6.300000</td>
      <td>1.300000</td>
      <td>0.4</td>
      <td>3.2</td>
      <td>2.000000</td>
      <td>25.500000</td>
      <td>0.0</td>
      <td>37.000000</td>
      <td>2</td>
      <td>96</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Luka Doncic</td>
      <td>2021-22</td>
      <td>141.0</td>
      <td>22.0</td>
      <td>65.000000</td>
      <td>65.000000</td>
      <td>35.4</td>
      <td>9.900000</td>
      <td>21.600000</td>
      <td>0.457000</td>
      <td>3.100000</td>
      <td>8.800000</td>
      <td>0.353000</td>
      <td>6.800000</td>
      <td>12.800000</td>
      <td>0.528</td>
      <td>0.529000</td>
      <td>5.600000</td>
      <td>7.500000</td>
      <td>0.744000</td>
      <td>0.9</td>
      <td>8.300000</td>
      <td>9.1</td>
      <td>8.700000</td>
      <td>1.200000</td>
      <td>0.6</td>
      <td>4.5</td>
      <td>2.200000</td>
      <td>28.400000</td>
      <td>0.0</td>
      <td>46.300000</td>
      <td>7</td>
      <td>95</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Jayson Tatum</td>
      <td>2021-22</td>
      <td>526.0</td>
      <td>23.0</td>
      <td>76.000000</td>
      <td>76.000000</td>
      <td>35.9</td>
      <td>9.300000</td>
      <td>20.600000</td>
      <td>0.453000</td>
      <td>3.000000</td>
      <td>8.600000</td>
      <td>0.353000</td>
      <td>6.300000</td>
      <td>12.000000</td>
      <td>0.524</td>
      <td>0.526000</td>
      <td>5.300000</td>
      <td>6.200000</td>
      <td>0.853000</td>
      <td>1.1</td>
      <td>6.900000</td>
      <td>8.0</td>
      <td>4.400000</td>
      <td>1.000000</td>
      <td>0.6</td>
      <td>2.9</td>
      <td>2.300000</td>
      <td>26.900000</td>
      <td>0.0</td>
      <td>39.300000</td>
      <td>9</td>
      <td>93</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Ja Morant</td>
      <td>2021-22</td>
      <td>390.0</td>
      <td>22.0</td>
      <td>57.000000</td>
      <td>57.000000</td>
      <td>33.1</td>
      <td>10.200000</td>
      <td>20.600000</td>
      <td>0.493000</td>
      <td>1.500000</td>
      <td>4.500000</td>
      <td>0.344000</td>
      <td>8.600000</td>
      <td>16.200000</td>
      <td>0.534</td>
      <td>0.530000</td>
      <td>5.500000</td>
      <td>7.300000</td>
      <td>0.761000</td>
      <td>1.4</td>
      <td>4.400000</td>
      <td>5.7</td>
      <td>6.700000</td>
      <td>1.200000</td>
      <td>0.4</td>
      <td>3.4</td>
      <td>1.500000</td>
      <td>27.400000</td>
      <td>0.0</td>
      <td>39.900000</td>
      <td>9</td>
      <td>93</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Jimmy Butler</td>
      <td>2021-22</td>
      <td>87.0</td>
      <td>32.0</td>
      <td>57.000000</td>
      <td>57.000000</td>
      <td>33.9</td>
      <td>7.000000</td>
      <td>14.500000</td>
      <td>0.480000</td>
      <td>0.500000</td>
      <td>2.000000</td>
      <td>0.233000</td>
      <td>6.500000</td>
      <td>12.500000</td>
      <td>0.520</td>
      <td>0.496000</td>
      <td>6.900000</td>
      <td>8.000000</td>
      <td>0.870000</td>
      <td>1.8</td>
      <td>4.100000</td>
      <td>5.9</td>
      <td>5.500000</td>
      <td>1.600000</td>
      <td>0.5</td>
      <td>2.1</td>
      <td>1.500000</td>
      <td>21.400000</td>
      <td>0.0</td>
      <td>32.800000</td>
      <td>9</td>
      <td>93</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Devin Booker</td>
      <td>2021-22</td>
      <td>59.0</td>
      <td>25.0</td>
      <td>68.000000</td>
      <td>68.000000</td>
      <td>34.5</td>
      <td>9.700000</td>
      <td>20.900000</td>
      <td>0.466000</td>
      <td>2.700000</td>
      <td>7.000000</td>
      <td>0.383000</td>
      <td>7.000000</td>
      <td>13.900000</td>
      <td>0.508</td>
      <td>0.530000</td>
      <td>4.600000</td>
      <td>5.300000</td>
      <td>0.868000</td>
      <td>0.7</td>
      <td>4.400000</td>
      <td>5.0</td>
      <td>4.800000</td>
      <td>1.100000</td>
      <td>0.4</td>
      <td>2.4</td>
      <td>2.600000</td>
      <td>26.800000</td>
      <td>0.0</td>
      <td>36.700000</td>
      <td>12</td>
      <td>91</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Trae Young</td>
      <td>2021-22</td>
      <td>602.0</td>
      <td>23.0</td>
      <td>76.000000</td>
      <td>76.000000</td>
      <td>34.9</td>
      <td>9.400000</td>
      <td>20.300000</td>
      <td>0.460000</td>
      <td>3.100000</td>
      <td>8.000000</td>
      <td>0.382000</td>
      <td>6.300000</td>
      <td>12.300000</td>
      <td>0.512</td>
      <td>0.536000</td>
      <td>6.600000</td>
      <td>7.300000</td>
      <td>0.904000</td>
      <td>0.7</td>
      <td>3.100000</td>
      <td>3.7</td>
      <td>9.700000</td>
      <td>0.900000</td>
      <td>0.1</td>
      <td>4.0</td>
      <td>1.700000</td>
      <td>28.400000</td>
      <td>0.0</td>
      <td>41.900000</td>
      <td>13</td>
      <td>90</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Anthony Davis</td>
      <td>2021-22</td>
      <td>127.0</td>
      <td>28.0</td>
      <td>40.000000</td>
      <td>40.000000</td>
      <td>35.1</td>
      <td>9.300000</td>
      <td>17.400000</td>
      <td>0.532000</td>
      <td>0.300000</td>
      <td>1.800000</td>
      <td>0.186000</td>
      <td>8.900000</td>
      <td>15.600000</td>
      <td>0.571</td>
      <td>0.542000</td>
      <td>4.400000</td>
      <td>6.100000</td>
      <td>0.713000</td>
      <td>2.7</td>
      <td>7.200000</td>
      <td>9.9</td>
      <td>3.100000</td>
      <td>1.200000</td>
      <td>2.3</td>
      <td>2.1</td>
      <td>2.400000</td>
      <td>23.200000</td>
      <td>0.0</td>
      <td>36.200000</td>
      <td>13</td>
      <td>90</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Chris Paul</td>
      <td>2021-22</td>
      <td>438.0</td>
      <td>36.0</td>
      <td>65.000000</td>
      <td>65.000000</td>
      <td>32.9</td>
      <td>5.600000</td>
      <td>11.300000</td>
      <td>0.493000</td>
      <td>1.000000</td>
      <td>3.100000</td>
      <td>0.317000</td>
      <td>4.600000</td>
      <td>8.300000</td>
      <td>0.559</td>
      <td>0.536000</td>
      <td>2.600000</td>
      <td>3.100000</td>
      <td>0.837000</td>
      <td>0.3</td>
      <td>4.000000</td>
      <td>4.4</td>
      <td>10.800000</td>
      <td>1.900000</td>
      <td>0.3</td>
      <td>2.4</td>
      <td>2.100000</td>
      <td>14.700000</td>
      <td>0.0</td>
      <td>29.800000</td>
      <td>13</td>
      <td>90</td>
      <td>2022</td>
    </tr>
    <tr>
      <th>15</th>
      <td>James Harden</td>
      <td>2021-22</td>
      <td>218.0</td>
      <td>32.0</td>
      <td>43.333333</td>
      <td>43.333333</td>
      <td>37.3</td>
      <td>6.133333</td>
      <td>14.966667</td>
      <td>0.408667</td>
      <td>2.266667</td>
      <td>6.866667</td>
      <td>0.329333</td>
      <td>3.866667</td>
      <td>8.133333</td>
      <td>0.476</td>
      <td>0.484667</td>
      <td>7.333333</td>
      <td>8.366667</td>
      <td>0.879333</td>
      <td>0.8</td>
      <td>6.766667</td>
      <td>7.6</td>
      <td>10.333333</td>
      <td>1.266667</td>
      <td>0.5</td>
      <td>4.2</td>
      <td>2.366667</td>
      <td>21.833333</td>
      <td>0.0</td>
      <td>39.733333</td>
      <td>16</td>
      <td>89</td>
      <td>2022</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-a9f8c235-9b69-4fd8-9222-a7612f0206c1')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-a9f8c235-9b69-4fd8-9222-a7612f0206c1 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-a9f8c235-9b69-4fd8-9222-a7612f0206c1');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell markdown" id="KFky0sv1M50F">
<p>To see if the data follows the same distribution after cleaning and dropping unnecessary information from the original dataset I plotted the same statistics in violin plot form. As expected the data follows the same distribution while being unimodal and skewed upward. The only difference is that there is a peak around the 15-stat mark whereas previously the mark was around the 10-stat mark.</p>
</div>
<div class="cell code" data-execution_count="190" data-colab="{&quot;height&quot;:295,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="oyagS_KTgJmW" data-outputId="f16b7a5d-e21d-4b2a-8830-f4bee1c49e32">
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make column for points + rebounds + assists for our final data fully cleaned data set</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;pts_reb_ast&#39;</span>] <span class="op">=</span> test.AST <span class="op">+</span> test.PTS <span class="op">+</span> test.ORB <span class="op">+</span> test.DRB</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the data</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>pl <span class="op">=</span> sns.violinplot(data <span class="op">=</span> test, x<span class="op">=</span><span class="st">&quot;year&quot;</span>, y<span class="op">=</span><span class="st">&quot;pts_reb_ast&quot;</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>pl.set_title(<span class="st">&#39;Pts+Reb+Ast Distribution Over Time&#39;</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>pl.set_xlabel(<span class="st">&quot;Season&quot;</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>pl.set_ylabel(<span class="st">&quot;Pts+Reb+Ast&quot;</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>pl.invert_xaxis()</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the distribution of the data as a violin plot</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co"># x-axis for the plot is time in years and y-axis is the Points + Rebounds + Assists </span></span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_50d0c7215e224aa8a1e2703691f9c7da/b07b563a666e74e9b062d22db984dd5a33ff9a1a.png" /></p>
</div>
</div>
<section id="data-exploration-and-analysis" class="cell markdown" id="IgZjPHLZhHJO">
<h1>Data Exploration and Analysis</h1>
</section>
<section id="exploration-on-points-vs-2k-rating" class="cell markdown" id="0czuFYxweT8b">
<h1>Exploration on Points vs 2k Rating</h1>
</section>
<div class="cell markdown" id="VGY-WLAWPgY0">
<p>The goal of this tutorial is to find a number rating that corresponds to the stats that the player produces so this would be classified as a regression problem. I want to use 2 different regression methods to try to predict the rating. I have to use the original linear regression and then I want to see how well KNN Regressor does when predicting the rating. The questions I want to answer are 1 "Is there a relationship between Points and 2kRating?" 2 "How much of a relationship?" 3 Repeat for pts+reb+ast 4 Then use KNN Regressor</p>
<p>First I want to use just the points stat to predict the rating because, in theory, the person that produces the most points should be the best player and thus have the highest rating. This is only in theory because basketball in real life is not only revolved around getting points. You have to be versatile and be able to produce in all aspects of the game to be considered a really good player. Because of this, we will then move onto linear regression with interaction terms between points, rebounds, and assists because they should all affect the rating. After the interaction term linear regression, I want to try out the regression with the pts+ast+reb column we used to plot the violin plots in the previous part.</p>
</div>
<div class="cell code" data-execution_count="191" data-colab="{&quot;height&quot;:639,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="Bj3XO_hjcMR6" data-outputId="88584017-4598-46d1-fc7a-30071a4ed970">
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Points vs. 2k Ratings</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>fig, t_plot <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>t_plot <span class="op">=</span> sns.regplot(test.PTS, test.Rating, color <span class="op">=</span> <span class="st">&quot;red&quot;</span>, scatter_kws<span class="op">=</span>{<span class="st">&#39;alpha&#39;</span>:<span class="fl">0.5</span>})</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>t_plot.set_title(<span class="st">&#39;Points vs 2k Rating&#39;</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>t_plot.set_xlabel(<span class="st">&quot;Points&quot;</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>t_plot.set_ylabel(<span class="st">&quot;2k Rating&quot;</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># x-axis for the plot is Points and y-axis is the 2k Rating</span></span></code></pre></div>
<div class="output execute_result" data-execution_count="191">
<pre><code>Text(0, 0.5, &#39;2k Rating&#39;)</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_50d0c7215e224aa8a1e2703691f9c7da/e7982afbb3040611e1a1893f4a89dd21a0e38b45.png" /></p>
</div>
</div>
<div class="cell markdown" id="oJgY6dqbB2Sz">
<p>We can see that as the number of points increases so do the 2kratings. There is a clear linear correlation between points and a 2k rating but the goal is to see how much of a correlation and to try to predict future ratings based on points alone.</p>
</div>
<section id="linear-regression-analysis" class="cell markdown" id="1s4dy2RUFibm">
<h1>Linear Regression Analysis</h1>
</section>
<div class="cell code" data-execution_count="192" data-colab="{&quot;height&quot;:541,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="JQR4Wer4RKTC" data-outputId="ca21d3bc-b624-4004-9903-6335f103db0d">
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>extra <span class="op">=</span> pd.DataFrame(columns <span class="op">=</span> [<span class="st">&quot;Algorithm&quot;</span>, <span class="st">&quot;Ind Var&quot;</span>, <span class="st">&quot;Mean Absolute Error&quot;</span>, <span class="st">&quot;R2&quot;</span>])</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># declare and intialize linear regression object</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>linear <span class="op">=</span> linear_model.LinearRegression()</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Average Player: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(test[<span class="st">&#39;PTS&#39;</span>].mean()) <span class="op">+</span> <span class="st">&quot;, &quot;</span> <span class="op">+</span> <span class="bu">str</span>(test[<span class="st">&#39;Rating&#39;</span>].mean()))</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>pts <span class="op">=</span> test[<span class="st">&#39;PTS&#39;</span>].array</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>rating <span class="op">=</span> test[<span class="st">&#39;Rating&#39;</span>].array  </span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model with points array and 2k Rating data from data frame</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>linear.fit(pts.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), rating)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Use ordinary least squares to fit the data and use ols to read only the array and 2k Rating data.</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>first <span class="op">=</span> sm.OLS.from_formula(<span class="st">&#39;Rating ~ PTS&#39;</span>, test).fit()</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>corr, _ <span class="op">=</span> pearsonr(test[<span class="st">&#39;PTS&#39;</span>],  test[<span class="st">&#39;Rating&#39;</span>])</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Using the linear regression object print the coefficient and intercept from the model</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Linear Regression Formula: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(linear.coef_[<span class="dv">0</span>]) <span class="op">+</span> <span class="st">&quot;x + &quot;</span> <span class="op">+</span> <span class="bu">str</span>(linear.intercept_) <span class="op">+</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Mean Residuals: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">abs</span>(first.resid).mean()))</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Pearson Correlation: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(corr))</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Double check the values are correct by running the ols summary to compare the coefficients and intercepts</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>first.summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Average Player: 11.00954756146715, 77.58645707376058
Linear Regression Formula: 0.781094457673584x + 68.98696049200487

Mean Residuals: 1.8422989081814336
Pearson Correlation: 0.8916107267764348
</code></pre>
</div>
<div class="output execute_result" data-execution_count="192">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.795</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.795</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6405.</td>
</tr>
<tr>
  <th>Date:</th>             <td>Wed, 14 Dec 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>22:47:48</td>     <th>  Log-Likelihood:    </th> <td> -3836.4</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>  1654</td>      <th>  AIC:               </th> <td>   7677.</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>  1652</td>      <th>  BIC:               </th> <td>   7688.</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>   68.9870</td> <td>    0.123</td> <td>  559.355</td> <td> 0.000</td> <td>   68.745</td> <td>   69.229</td>
</tr>
<tr>
  <th>PTS</th>       <td>    0.7811</td> <td>    0.010</td> <td>   80.033</td> <td> 0.000</td> <td>    0.762</td> <td>    0.800</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>251.152</td> <th>  Durbin-Watson:     </th> <td>   1.546</td> 
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 918.037</td> 
</tr>
<tr>
  <th>Skew:</th>          <td> 0.714</td>  <th>  Prob(JB):          </th> <td>4.48e-200</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 6.359</td>  <th>  Cond. No.          </th> <td>    25.9</td> 
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</div>
</div>
<div class="cell markdown" id="LNtTB29c6ZF7">
<p>We can see that there is a positive correlation between the independent variable, points, such that as the number of points increases so does the 2k rating. From the regression formula we can see that for every one point a player increases they increase their total rating by .781. We can see that the average player scores around 11 points per game and are listed at a 78 rating. This can be used as a basis for classifying and rating great players because many of the players who are rated in the 90s are averaging above 20 points per game. We can see that there is a correlation before a correlation test is even administered purely off on the analysis of the stats. As a cherry on top according to the Pearson correlation test we can see that the correlation between points and rating is 0.8916107267764348. This suggests that there is a strong positive correlation between the two which is then supported by our linear regression.</p>
</div>
<div class="cell code" data-execution_count="193" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="MBUnEaSEE8Bq" data-outputId="ad46c704-814f-49ac-96e5-e009f6724e9b">
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the independent and dependent variable for the linear regression model</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># In this case it is points as independent variable and 2k rating as dependent</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>X,Y <span class="op">=</span> test[[<span class="st">&#39;PTS&#39;</span>]], test.Rating</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>x_train, x_test,y_train,y_test <span class="op">=</span> train_test_split(X,Y,test_size <span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>linear_test <span class="op">=</span> linear_model.LinearRegression()</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co"># fit the model with the training set</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>linear_test.fit(x_train,y_train)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>linear_test.predict(x_test)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co"># test and score the model with the test set</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Linear Regression Test Set R2: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(linear_test.score(x_test,y_test)))</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="co"># run 10 fold cross validation on mean absolute error to evaluate the model</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>scores_lin_pts <span class="op">=</span> cross_val_score(linear_test, X, Y, scoring<span class="op">=</span><span class="st">&#39;neg_mean_absolute_error&#39;</span>, cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>extra <span class="op">=</span> extra.append({<span class="st">&quot;Algorithm&quot;</span>: <span class="st">&quot;Linear Regression&quot;</span>, <span class="st">&quot;Ind Var&quot;</span>: <span class="st">&quot;Points&quot;</span>, <span class="st">&quot;Mean Absolute Error&quot;</span> : <span class="bu">abs</span>(scores_lin_pts).mean(),<span class="st">&quot;R2&quot;</span>: linear_test.score(x_test,y_test)}, ignore_index <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Linear Regression 10 Fold Cross Validation Scores: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">abs</span>(scores_lin_pts)) <span class="op">+</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Linear Regression Mean Absolute Error of 10 Fold Cross Validation: &quot;</span>  <span class="op">+</span> <span class="bu">str</span>(<span class="bu">abs</span>(scores_lin_pts).mean()))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Linear Regression Test Set R2: 0.7862904600502281
Linear Regression 10 Fold Cross Validation Scores: [2.12173905 1.59765624 2.16245645 1.60199682 1.89244352 1.47868778
 2.16823212 1.69421653 2.27201333 1.63549204]

Linear Regression Mean Absolute Error of 10 Fold Cross Validation: 1.8624933875119285
</code></pre>
</div>
</div>
<div class="cell markdown" id="melkMirYDshf">
<p>We can see that the after fitting the model with the training data and scoring the test data the R2 value is about 0.82. This is a value close to one so this would indicate that we can assume that the linear regression model is a good fit for the dependent variable. To confirm this I performed a 10 Fold Cross Validation based on the Mean absolute error. Based on the results of the 10 Fold Cross validation we can see the average mean absolute error is relatively low. We can interpret this as the error between the prediction and the actual value is around 1.86 overall. To put this in perspective the average 2k rating is about 78 so if the average of the absolute error between the prediction and the actual value is about 2 percent of the total value then we can say that the prediction is relatively accurate.</p>
</div>
<section id="k-nearest-neighbor-analysis" class="cell markdown" id="okFxONfRFnXJ">
<h1>K Nearest Neighbor Analysis</h1>
</section>
<div class="cell markdown" id="W0yEQD9jtYQp">
<p>To have some fun and mess around I wanted to test out how the KNN regressor would do with predicting 2k ratings based on the points alone. Since many of the neighbors to the points will have around the same points scored I expect the algorithm to do decently well when predicting ratings because the ratings close by should be a good representation of what rating the prediction point should be. KNN is not the only regression algorithm I could have chosen but I based on the data and situation I wanted to use this algorithm specifically. If you want to see the other options for machine learning algorithms you can go here <a href="https://scikit-learn.org/stable/">ML Algorithms</a></p>
</div>
<div class="cell markdown" id="_T5SYrjUvGzA">
<p>Hyperparameter tuning is crucial when trying to apply a machine learning model because it will a really good hyperparameter value will in turn allow the model to be the best it can be. The hyperparameter for K nearest neighbor is K. So the number of neighbors it will look at to predict the next value. To find the best k I am using a popular method for hyperparameter tuning called grid search cv. If you want to learn about gridsearchcv you can go here <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html">GridSearchCV</a> Grid search cv is not the only hyperparameter tuning function but seemed the most straight forward so I used it. There are a couple of others like random search, Bayesian Optimization, etc.</p>
</div>
<div class="cell code" data-execution_count="194" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="cwC0BljJGQL0" data-outputId="a7a1315b-d1d3-4be6-be7a-e4ad7795e467">
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># declare and intialize linear regression object</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>neigh_pts <span class="op">=</span> neighbors.KNeighborsRegressor()</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>parameters <span class="op">=</span> [{<span class="st">&#39;n_neighbors&#39;</span>: [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span> , <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>]}]</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Find best K using gridsearchcv</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>param_search <span class="op">=</span> GridSearchCV(neigh_pts, parameters, scoring <span class="op">=</span> <span class="st">&#39;neg_mean_absolute_error&#39;</span>, cv <span class="op">=</span> <span class="dv">5</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>param_search.fit(X, Y)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(param_search.best_params_)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="co"># The process to find the best hyperparameter for the KNN algorithn helps us get the best result possible.</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co"># By finding how many neighbors to search for and compare the algorithm is a lot better at predicting the next value.</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>{&#39;n_neighbors&#39;: 10}
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="195" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="FTc0q17jGP2x" data-outputId="507c255a-873c-4cc3-91f6-d1734dc01892">
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the independent and dependent variable for the KNN regression model</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># In this case it is points as independent variable and 2k rating as dependent</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># fit the model with the training set</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>neigh_pts.fit(x_train,y_train)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>neigh_pts.predict(x_test)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co"># test and score the model with the test set</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;KNN Test Set R2: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(neigh_pts.score(x_test,y_test)))</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co"># run 10 fold cross validation on mean absolute error to evaluate the model</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>scores_pts <span class="op">=</span> cross_val_score(neigh_pts, X, Y, scoring<span class="op">=</span><span class="st">&#39;neg_mean_absolute_error&#39;</span>, cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>extra <span class="op">=</span> extra.append({<span class="st">&quot;Algorithm&quot;</span>: <span class="st">&quot;K Nearest Neighbor Regression&quot;</span>, <span class="st">&quot;Ind Var&quot;</span>: <span class="st">&quot;Points&quot;</span>, <span class="st">&quot;Mean Absolute Error&quot;</span> : <span class="bu">abs</span>(scores_pts).mean(),<span class="st">&quot;R2&quot;</span>: neigh_pts.score(x_test,y_test)}, ignore_index <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;KNN 10 Fold Cross Validation Scores: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">abs</span>(scores_pts)) <span class="op">+</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;KNN Mean Absolute Error of 10 Fold Cross Validation: &quot;</span>  <span class="op">+</span> <span class="bu">str</span>(<span class="bu">abs</span>(scores_pts).mean()))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>KNN Test Set R2: 0.7507204796746897
KNN 10 Fold Cross Validation Scores: [2.40963855 1.76024096 2.44939759 1.64457831 2.14424242 1.52969697
 2.42060606 1.76848485 2.30545455 1.68727273]

KNN Mean Absolute Error of 10 Fold Cross Validation: 2.0119612997444323
</code></pre>
</div>
</div>
<div class="cell markdown" id="IwW77oqYxQt4">
<p>We can see that the R2 for the KNN is around 0.8. This is relatively close to 1 so this would me that this model is a good fit for the dependent variable. We can see that the average mean absolute error is about 2.01. This is a relatively low absolute in terms of a 2k rating because the rating average is about 78. The mean absolute error is about 2 percent of the total rating so the model is a good fit for the data. Because the mean absolute value is low we can accurately predict the 2k ratings based on the points.</p>
</div>
<section id="comparison" class="cell markdown" id="PukprmdBbHoI">
<h1>Comparison</h1>
</section>
<div class="cell code" data-execution_count="196" data-colab="{&quot;height&quot;:112,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="7COA0ImoTKpE" data-outputId="6edb74e5-65de-4940-e9e8-fa214feb506a">
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>extra</span></code></pre></div>
<div class="output execute_result" data-execution_count="196">

  <div id="df-e3d6b527-fa31-44bb-8a6f-8a4eb1f7a8cf">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Algorithm</th>
      <th>Ind Var</th>
      <th>Mean Absolute Error</th>
      <th>R2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Linear Regression</td>
      <td>Points</td>
      <td>1.862493</td>
      <td>0.78629</td>
    </tr>
    <tr>
      <th>1</th>
      <td>K Nearest Neighbor Regression</td>
      <td>Points</td>
      <td>2.011961</td>
      <td>0.75072</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-e3d6b527-fa31-44bb-8a6f-8a4eb1f7a8cf')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-e3d6b527-fa31-44bb-8a6f-8a4eb1f7a8cf button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-e3d6b527-fa31-44bb-8a6f-8a4eb1f7a8cf');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell markdown" id="6FFI3pAzxAgQ">
<p>Both algorithms are very similar in terms of R2 and mean absolute error but linear regression takes a slight edge in both evaluation methods. When it comes to R2, the linear regression method was always slightly higher than the KNN algorithm. Both are relatively good but linear regression is better a fit for the dependent variable. When it came to mean absolute error, the linear regression algorithm was around 1.86 while the KNN algorithm was around 2.01. We can see that linear regression has about 8 percent less mean absolute error than KNN. We can see that both algorithms can be used in this situation but in terms of better predictions, we can stick with the linear regression because we want to reduce the amount of error between predicted and actual values as much as possible.</p>
</div>
<section id="exploration-on-pointsreboundsassists-vs-2k-rating" class="cell markdown" id="Rru7GJ-jv9cX">
<h1>Exploration on Points+Rebounds+Assists vs. 2k Rating</h1>
</section>
<div class="cell markdown" id="Fx95CDFqBH7f">
<p>Points are only a part of the story when finding a good player. Being able to rebound the ball and assist your teammates along with being able to score is what differentiates great players from average players. So in terms of 2k ratings, the number of Points, Rebounds, and Assists should all affect that rating. To account for this I decided to add up all of the stats together and create a separate column for that stat. In this way, it's a lot easier to understand and a lot easier to compute manually. Based on the pts in the previous section, we should see a similar trend such that an increase in the Points+Rebounds+Assists mark should be linked with an increase in rating.</p>
</div>
<div class="cell code" data-execution_count="197" data-colab="{&quot;height&quot;:639,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="CSqDclcewFrD" data-outputId="16709ec9-32ed-44d7-ad21-201963720c1a">
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Points+Rebounds+Assists vs. 2k Ratings</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>fig, t_plot <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>t_plot <span class="op">=</span> sns.regplot(test.pts_reb_ast, test.Rating, color <span class="op">=</span> <span class="st">&quot;green&quot;</span>, scatter_kws<span class="op">=</span>{<span class="st">&#39;alpha&#39;</span>:<span class="fl">0.5</span>})</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>t_plot.set_title(<span class="st">&#39;Points+Rebounds+Assists vs 2k Rating&#39;</span>)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>t_plot.set_xlabel(<span class="st">&quot;Points+Rebounds+Assists&quot;</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>t_plot.set_ylabel(<span class="st">&quot;2k Rating&quot;</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co"># x-axis for the plot is Points+Rebounds+Assists and y-axis is the 2k Rating</span></span></code></pre></div>
<div class="output execute_result" data-execution_count="197">
<pre><code>Text(0, 0.5, &#39;2k Rating&#39;)</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_50d0c7215e224aa8a1e2703691f9c7da/3ef13696b7d007b7c7ee4d3bec3f51dbad0debba.png" /></p>
</div>
</div>
<div class="cell markdown" id="8PAtI1hpCMa7">
<p>Like the points plot, we can see that the stats combined also tend to have a positive linear correlation. This graph seems to be a little more tightly wound along the regression line so this should have a better ability to predict 2k ratings since we get also get a better picture of the player since we have more than one stat to base the prediction of.</p>
</div>
<section id="linear-regression-analysis" class="cell markdown" id="c8jUFn5VNrI6">
<h1>Linear Regression Analysis</h1>
</section>
<div class="cell code" data-execution_count="198" data-colab="{&quot;height&quot;:541,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="C8ViTycfxJb_" data-outputId="46930460-7d89-4752-97d7-9afec78bea0d">
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># declare and intialize linear regression object</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>linear_imp_stats <span class="op">=</span> linear_model.LinearRegression()</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Average Player: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(test[<span class="st">&#39;pts_reb_ast&#39;</span>].mean()) <span class="op">+</span> <span class="st">&quot;, &quot;</span> <span class="op">+</span> <span class="bu">str</span>(test[<span class="st">&#39;Rating&#39;</span>].mean()))</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>stat_imp <span class="op">=</span> test[<span class="st">&#39;pts_reb_ast&#39;</span>].array</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>rating <span class="op">=</span> test[<span class="st">&#39;Rating&#39;</span>].array  </span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model with Points+Rebounds+Assists array and 2k Rating data from data frame</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>linear_imp_stats.fit(stat_imp.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), rating)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Use ordinary least squares to fit the data and use ols to read only the array and 2k Rating data.</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>first_imp <span class="op">=</span> sm.OLS.from_formula(<span class="st">&#39;Rating ~ pts_reb_ast&#39;</span>, test).fit()</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>corr, _ <span class="op">=</span> pearsonr(test[<span class="st">&#39;pts_reb_ast&#39;</span>],  test[<span class="st">&#39;Rating&#39;</span>])</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Using the linear regression object print the coefficient and intercept from the model</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Linear Regression Formula: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(linear_imp_stats.coef_[<span class="dv">0</span>]) <span class="op">+</span> <span class="st">&quot;x + &quot;</span> <span class="op">+</span> <span class="bu">str</span>(linear_imp_stats.intercept_) <span class="op">+</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Mean Residuals: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">abs</span>(first_imp.resid).mean()))</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Pearson Correlation: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(corr))</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Double check the values are correct by running the ols summary to compare the coefficients and intercepts</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>first_imp.summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Average Player: 17.859356106408708, 77.58645707376058
Linear Regression Formula: 0.5512674358386024x + 67.74117562725218

Mean Residuals: 1.5802925807184853
Pearson Correlation: 0.9200346799349055
</code></pre>
</div>
<div class="output execute_result" data-execution_count="198">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.846</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.846</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9108.</td>
</tr>
<tr>
  <th>Date:</th>             <td>Wed, 14 Dec 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>22:47:49</td>     <th>  Log-Likelihood:    </th> <td> -3597.2</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>  1654</td>      <th>  AIC:               </th> <td>   7198.</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>  1652</td>      <th>  BIC:               </th> <td>   7209.</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>   <td>   67.7412</td> <td>    0.116</td> <td>  585.463</td> <td> 0.000</td> <td>   67.514</td> <td>   67.968</td>
</tr>
<tr>
  <th>pts_reb_ast</th> <td>    0.5513</td> <td>    0.006</td> <td>   95.434</td> <td> 0.000</td> <td>    0.540</td> <td>    0.563</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>351.875</td> <th>  Durbin-Watson:     </th> <td>   1.620</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2668.851</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.783</td>  <th>  Prob(JB):          </th> <td>    0.00</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 9.023</td>  <th>  Cond. No.          </th> <td>    44.3</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</div>
</div>
<div class="cell markdown" id="ke5Ix4geW8qT">
<p>We assumed that there was a positive correlation between the pts+reb+ast and 2k rating from the observations made in the graph. There is clear statistical evidence backing this claim because we can see that the coefficient for the regression line is positive. This positive coefficient indicates that for 1 stat the pts+reb+ast increases the 2k rating increases by 0.551267435. We can see that the average player produces around 17.85 pts+reb+ast and the average player has a 2k rating of about 78. Again this can be used as a basis/level 0 to work off of because if a player produces less or produces more they become a better/worse player which should correlate to their rating fluctuating based on performance.</p>
<p>We can see from the graph and the linear regression line formula that there is a pattern that the 2k ratings follow that somewhat follow the pts+reb+ast. To confirm there is a correlation we can see that the Pearson correlation test has a result of 0.9200346799349055. This means that there is a very strong positive correlation between pts+reb+ast and 2k rating. Compared to points alone to the pts+reb+ast stat, pts+reb+ast is 0.028423953158470683 higher in terms of correlation test results. This would indicate that there is more of a correlation between pts+reb+asts and 2k rating than between just points and 2k rating.</p>
</div>
<div class="cell code" data-execution_count="199" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="1iY0hb4CxNAm" data-outputId="3dd07cd3-894b-42c6-e525-c7aba3d728d7">
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the independent and dependent variable for the linear regression model</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co"># In this case it is points as independent variable and 2k rating as dependent</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>X_all,Y_all <span class="op">=</span> test[[<span class="st">&#39;pts_reb_ast&#39;</span>]], test.Rating</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>x_train_all, x_test_all,y_train_all,y_test_all <span class="op">=</span> train_test_split(X_all,Y_all,test_size <span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>linear_test_imp <span class="op">=</span> linear_model.LinearRegression()</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="co"># fit the model with the training set</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>linear_test_imp.fit(x_train_all,y_train_all)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>linear_test_imp.predict(x_test_all)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="co"># score the model for the test sets</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Set R2: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(linear_test_imp.score(x_test_all,y_test_all)))</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="co"># run the 10 fold cross validation based on mean absolute error to evaluate model</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> cross_val_score(linear_test_imp, X_all, Y_all, scoring<span class="op">=</span><span class="st">&#39;neg_mean_absolute_error&#39;</span>, cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>extra <span class="op">=</span> extra.append({<span class="st">&quot;Algorithm&quot;</span>: <span class="st">&quot;Linear Regression&quot;</span>, <span class="st">&quot;Ind Var&quot;</span>: <span class="st">&quot;Pts+Reb+Ast&quot;</span>, <span class="st">&quot;Mean Absolute Error&quot;</span> : <span class="bu">abs</span>(scores).mean(),<span class="st">&quot;R2&quot;</span>: linear_test_imp.score(x_test_all,y_test_all)}, ignore_index <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;10 Fold Cross Validation Scores: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">abs</span>(scores)) <span class="op">+</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Mean Absolute Error of 10 Fold Cross Validation: &quot;</span>  <span class="op">+</span> <span class="bu">str</span>(<span class="bu">abs</span>(scores).mean()))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Test Set R2: 0.8788486154440434
10 Fold Cross Validation Scores: [1.708322   1.47864001 1.68172122 1.51169917 1.45483377 1.44182014
 1.67393295 1.6008755  1.87654215 1.46933385]

Mean Absolute Error of 10 Fold Cross Validation: 1.5897720782724354
</code></pre>
</div>
</div>
<div class="cell markdown" id="upbTB1naa5XH">
<p>Compared to just points the R2 is around is a lot higher. The points R2 would be around the 0.82 mark but the pts+reb+ast has an R2 that is around the 0.85-0.87 mark. We can see that the linear regression model for pts+reb+ast is definitely a good fit for the dependent variable, 2k rating. The mean absolute error is also relatively much lower. The average mean absolute error went from around 1.86 to about 1.59. That is about 16% less error when using pts+reb+ast as opposed to just pts. We can see that because there is less error the regression line would be able to predict 2k ratings at a much more accurate and efficient rate.</p>
</div>
<section id="k-nearest-neighbor-analysis" class="cell markdown" id="t_DFBa8ONvcs">
<h1>K Nearest Neighbor Analysis</h1>
</section>
<div class="cell markdown" id="TrKZSZ8R4tXR">
<p>Again to have some fun, I wanted to see how well the KNN regressor algorithm did with the pts+reb+asts stat. So I implemented the same tactics for hyperparameter tuning as I did in the KNN for points and went on to test the KNN algorithm with the pts+reb+ast and 2k rating data</p>
</div>
<div class="cell code" data-execution_count="200" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="dHwgFCqsN2rr" data-outputId="90982186-9ea1-404f-a715-7accb75b2dc8">
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># declare and intialize linear regression object</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>neigh_all <span class="op">=</span> neighbors.KNeighborsRegressor()</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>parameters <span class="op">=</span> [{<span class="st">&#39;n_neighbors&#39;</span>: [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span> , <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>]}]</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Find best K using gridsearchcv</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>param_search <span class="op">=</span> GridSearchCV(neigh_all, parameters, scoring <span class="op">=</span> <span class="st">&#39;neg_mean_absolute_error&#39;</span>, cv <span class="op">=</span> <span class="dv">5</span>)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>param_search.fit(X_all, Y_all)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(param_search.best_params_)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co"># The process to find the best hyperparameter for the KNN algorithn helps us get the best result possible.</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co"># By finding how many neighbors to search for and compare the algorithm is a lot better at predicting the next value.</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>{&#39;n_neighbors&#39;: 10}
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="201" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="ABOgFCMkVJ0j" data-outputId="f2431f90-4bb3-4950-a9bd-2e2fe21401aa">
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the independent and dependent variable for the KNN regression model</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co"># In this case it is points as independent variable and 2k rating as dependent</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co"># fit the mode with the training sets</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>neigh_all.fit(x_train_all,y_train_all)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="co"># predict the prediction for the test set</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>neigh_all.predict(x_test_all)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co"># score for the test set</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;KNN All Test Set R2: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(neigh_all.score(x_test_all,y_test_all)))</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="co"># run the 10 fold cross validation based on mean absolute error to evaluate model</span></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>scores_all <span class="op">=</span> cross_val_score(neigh_all, X_all, Y_all, scoring<span class="op">=</span><span class="st">&#39;neg_mean_absolute_error&#39;</span>, cv<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="co"># add data to ml algo results data frame</span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>extra <span class="op">=</span> extra.append({<span class="st">&quot;Algorithm&quot;</span>: <span class="st">&quot;K Nearest Neighbor Regression&quot;</span>, <span class="st">&quot;Ind Var&quot;</span>: <span class="st">&quot;Pts+Reb+Ast&quot;</span>, <span class="st">&quot;Mean Absolute Error&quot;</span> : <span class="bu">abs</span>(scores_all).mean(),<span class="st">&quot;R2&quot;</span>: neigh_all.score(x_test_all,y_test_all)}, ignore_index <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;KNN All 10 Fold Cross Validation Scores: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">abs</span>(scores_all)) <span class="op">+</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;KNN All Mean Absolute Error of 10 Fold Cross Validation: &quot;</span>  <span class="op">+</span> <span class="bu">str</span>(<span class="bu">abs</span>(scores_all).mean()))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>KNN All Test Set R2: 0.8555474908937498
KNN All 10 Fold Cross Validation Scores: [1.81927711 1.41927711 1.94698795 1.41325301 1.74060606 1.26787879
 1.79151515 1.67272727 1.95757576 1.34545455]

KNN All Mean Absolute Error of 10 Fold Cross Validation: 1.637455275648047
</code></pre>
</div>
</div>
<div class="cell markdown" id="eVu2MjJ45s38">
<p>The R2 for all of the algorithms we have used has been relatively good. Since the value of R2 is close to 1, we can say that the model is a good fit for the dependent variable, a 2k rating. When we turn over to the scores of the 10 fold cross validation scores we can see that the average absolute mean error was around the 1.63 mark. This means that the average amount that we are usually off from the prediction is about 1.63. This is a good error to have because the average for a 2k rating is around 78 so we are only off by 1 or 2 ratings when predicting. The KNN for points was worse in terms of absolute mean error and R2 so we can see the improvement from just pts to pts+reb+ast.</p>
</div>
<section id="comparison" class="cell markdown" id="MO3JB7HkbMUM">
<h1>Comparison</h1>
</section>
<div class="cell code" data-execution_count="202" data-colab="{&quot;height&quot;:175,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="BamxlNulSKe9" data-outputId="f9f2d8a9-de05-4699-85c6-e2eae9eff658">
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>extra</span></code></pre></div>
<div class="output execute_result" data-execution_count="202">

  <div id="df-e89b1221-4602-4c9d-9d0d-e42518b13a5f">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Algorithm</th>
      <th>Ind Var</th>
      <th>Mean Absolute Error</th>
      <th>R2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Linear Regression</td>
      <td>Points</td>
      <td>1.862493</td>
      <td>0.786290</td>
    </tr>
    <tr>
      <th>1</th>
      <td>K Nearest Neighbor Regression</td>
      <td>Points</td>
      <td>2.011961</td>
      <td>0.750720</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Linear Regression</td>
      <td>Pts+Reb+Ast</td>
      <td>1.589772</td>
      <td>0.878849</td>
    </tr>
    <tr>
      <th>3</th>
      <td>K Nearest Neighbor Regression</td>
      <td>Pts+Reb+Ast</td>
      <td>1.637455</td>
      <td>0.855547</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-e89b1221-4602-4c9d-9d0d-e42518b13a5f')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-e89b1221-4602-4c9d-9d0d-e42518b13a5f button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-e89b1221-4602-4c9d-9d0d-e42518b13a5f');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell markdown" id="krCguI4Kbkcl">
<p>Like in the points vs. 2k rating analysis we can see that the linear regression model tends to have a slight edge over KNN. When it came to R2, the linear regression model was consistently around the 0.85-0.87 mark while the KNN algorithm was in the 0.82 area. This would allow us to assume that the linear regression fits the 2k ratings better. From the plots, we can see the linear relationship between pts+reb+ast and 2k rating so this would make sense. Again in the mean absolute error, we can see a slight discrepancy between KNN and linear regression. The linear regression algorithm for pts+reb+ast seems to be the best fit for a 2k rating and this directly correlates to having the least mean absolute error.</p>
</div>
<section id="conclusion" class="cell markdown" id="cIB5aAw3bkvG">
<h1>Conclusion</h1>
</section>
<div class="cell markdown" id="eCnKX6gRdnBH">
<p>All of the training models and results of these models were relatively good. They all showed us that it is possible to predict a player's 2k rating off either just points or points, rebounds, and assists pretty accurately. Even though all of the models resulted in low mean absolute errors when the 10-fold cross-validation was done, the best R2 score and lowest mean absolute error were definitely for the pts+reb+ast linear regression. Based on the plots in that section we could have observed the linear relationship between the independent variable and dependent variable and based on this observation it would have been clear that linear regression would be best in this situation. I expected K nearest neighbor to compete with linear regression because the stats had a lot of clusters. This would indicate that many of the ratings that were close by would also have the same stats. So if the prediction landed next to good neighbors then the ability for that model to predict the 2k rating should be accurate.</p>
<p>Based on the linear regression model for pts+reb+ast we can accurately predict the 2k rating for the player if we are given the number of points, assists, and rebounds they average within a year. To test this theory the best way is to predict the ratings for a data set that has not been rated yet and then compare when the ratings are released.</p>
</div>
<div class="cell markdown" id="IPVYJwPCyhyy">
<p><img src="vertopal_50d0c7215e224aa8a1e2703691f9c7da/a3aa4e254267ec26fb8e809778d8e58c4c8c313f.webp" alt="nba2k24-introducing-the-mamba-challenge-v0-7m7i06xot6z91.webp" /></p>
</div>
<div class="cell markdown" id="0naRRusfnjXT">
<p>As a final test, I gathered the data for the players as of December 14, 2022, and cleaned the data. Using this data, I wanted to predict the 2k rating for the players for 2k24. The model I choose was the one we decided was the best model to work with since it had the highest R2 and lowest mean absolute value. Using the pts+reb+ast linear regression model I predicted the 2k rating for the players based on how they have been playing so far. The goal is to come back in September 2023 when 2k24 releases and check how accurate the predictions were.</p>
</div>
<div class="cell code" data-execution_count="203" data-colab="{&quot;height&quot;:688,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="lyyAfMalVL8O" data-outputId="c5c82d9e-f1b0-47f8-dd5f-348ab82ff781">
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get data for 2022 year</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>players_stats_2023 <span class="op">=</span> pd.read_excel(<span class="st">&#39;/content/NBA Stats 202223 All Player Statistics in one Page.xlsx&#39;</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Name the columns since for some reason the data did not come labeled</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>players_stats_2023.columns <span class="op">=</span> [<span class="st">&#39;random&#39;</span>, <span class="st">&#39;Name&#39;</span>, <span class="st">&#39;Team&#39;</span>, <span class="st">&#39;Pos&#39;</span>, <span class="st">&#39;Age&#39;</span>, <span class="st">&quot;GP&quot;</span>, <span class="st">&#39;MPG&#39;</span>, <span class="st">&quot;Min%&quot;</span>, <span class="st">&quot;USG%&quot;</span>, <span class="st">&quot;TO%&quot;</span>, <span class="st">&quot;FTA&quot;</span>, <span class="st">&quot;FT%&quot;</span>, <span class="st">&quot;2PA&quot;</span>, <span class="st">&quot;2P%&quot;</span>, <span class="st">&quot;3PA&quot;</span>, <span class="st">&quot;3P%&quot;</span>, <span class="st">&quot;eFG%&quot;</span>, <span class="st">&quot;TS%&quot;</span>, <span class="st">&quot;PPG&quot;</span>, <span class="st">&quot;RPG&quot;</span>, <span class="st">&quot;TRB%&quot;</span>, <span class="st">&quot;APG&quot;</span>, <span class="st">&quot;AST%&quot;</span>, <span class="st">&quot;SPG&quot;</span>, <span class="st">&quot;BPG&quot;</span>, <span class="st">&quot;TOPG&quot;</span>, <span class="st">&quot;VI&quot;</span>, <span class="st">&quot;ORTG&quot;</span>, <span class="st">&quot;DRTG&quot;</span>]</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop columns because they had NaN values and are not needed for prediction</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>players_stats_2023 <span class="op">=</span> players_stats_2023.drop(columns <span class="op">=</span> {<span class="st">&#39;random&#39;</span>, <span class="st">&quot;ORTG&quot;</span>, <span class="st">&quot;DRTG&quot;</span> })</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop first row with unnecessary information </span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>players_stats_2023 <span class="op">=</span> players_stats_2023.drop( index <span class="op">=</span> <span class="dv">0</span>, axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Get pts+reb+ast for the 2022 dataset</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>players_stats_2023[<span class="st">&quot;pts_reb_ast&quot;</span>] <span class="op">=</span> players_stats_2023.PPG <span class="op">+</span> players_stats_2023.RPG <span class="op">+</span> players_stats_2023.APG </span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="co"># get the predictions from the model based on the pts+reb+ast</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>players_stats_2023[<span class="st">&quot;rating&quot;</span>] <span class="op">=</span> linear_test_imp.predict(players_stats_2023[[<span class="st">&quot;pts_reb_ast&quot;</span>]])</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="co"># switch rating to be in the first column so it is easily seen</span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>first_column <span class="op">=</span> players_stats_2023.pop(<span class="st">&#39;rating&#39;</span>)</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>players_stats_2023.insert(<span class="dv">0</span>, <span class="st">&#39;rating&#39;</span>, first_column)</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>players_stats_2023.head(<span class="dv">15</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="203">

  <div id="df-b64d5d53-9083-48bf-8d8f-b169df6352d7">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>rating</th>
      <th>Name</th>
      <th>Team</th>
      <th>Pos</th>
      <th>Age</th>
      <th>GP</th>
      <th>MPG</th>
      <th>Min%</th>
      <th>USG%</th>
      <th>TO%</th>
      <th>FTA</th>
      <th>FT%</th>
      <th>2PA</th>
      <th>2P%</th>
      <th>3PA</th>
      <th>3P%</th>
      <th>eFG%</th>
      <th>TS%</th>
      <th>PPG</th>
      <th>RPG</th>
      <th>TRB%</th>
      <th>APG</th>
      <th>AST%</th>
      <th>SPG</th>
      <th>BPG</th>
      <th>TOPG</th>
      <th>VI</th>
      <th>pts_reb_ast</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>77.210615</td>
      <td>Precious Achiuwa</td>
      <td>Tor</td>
      <td>F</td>
      <td>23.24</td>
      <td>12</td>
      <td>20.4</td>
      <td>42.5</td>
      <td>21</td>
      <td>12.3</td>
      <td>33</td>
      <td>0.848</td>
      <td>64</td>
      <td>0.484</td>
      <td>28</td>
      <td>0.179</td>
      <td>0.418</td>
      <td>0.493</td>
      <td>8.8</td>
      <td>7</td>
      <td>19.4</td>
      <td>1.3</td>
      <td>9.5</td>
      <td>0.17</td>
      <td>0.58</td>
      <td>1.25</td>
      <td>8.5</td>
      <td>17.1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>79.249532</td>
      <td>Steven Adams</td>
      <td>Mem</td>
      <td>C</td>
      <td>29.4</td>
      <td>24</td>
      <td>26.7</td>
      <td>55.6</td>
      <td>14.2</td>
      <td>23.1</td>
      <td>65</td>
      <td>0.292</td>
      <td>140</td>
      <td>0.614</td>
      <td>1</td>
      <td>0</td>
      <td>0.61</td>
      <td>0.563</td>
      <td>8</td>
      <td>10.5</td>
      <td>21</td>
      <td>2.3</td>
      <td>11.5</td>
      <td>0.79</td>
      <td>1.04</td>
      <td>2.13</td>
      <td>8.7</td>
      <td>20.8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>86.303086</td>
      <td>Bam Adebayo</td>
      <td>Mia</td>
      <td>C-F</td>
      <td>25.41</td>
      <td>26</td>
      <td>35</td>
      <td>73</td>
      <td>26.2</td>
      <td>14.4</td>
      <td>139</td>
      <td>0.842</td>
      <td>391</td>
      <td>0.54</td>
      <td>10</td>
      <td>0.1</td>
      <td>0.53</td>
      <td>0.586</td>
      <td>20.8</td>
      <td>9.5</td>
      <td>15.5</td>
      <td>3.3</td>
      <td>16.9</td>
      <td>0.96</td>
      <td>0.73</td>
      <td>3</td>
      <td>9.9</td>
      <td>33.6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>70.212167</td>
      <td>Ochai Agbaji</td>
      <td>Uta</td>
      <td>G</td>
      <td>22.65</td>
      <td>12</td>
      <td>9</td>
      <td>18.7</td>
      <td>13.6</td>
      <td>0</td>
      <td>7</td>
      <td>0.571</td>
      <td>18</td>
      <td>0.556</td>
      <td>14</td>
      <td>0.286</td>
      <td>0.5</td>
      <td>0.513</td>
      <td>3</td>
      <td>1.3</td>
      <td>7.6</td>
      <td>0.1</td>
      <td>1.2</td>
      <td>0.08</td>
      <td>0</td>
      <td>0</td>
      <td>3.2</td>
      <td>4.4</td>
    </tr>
    <tr>
      <th>5</th>
      <td>77.265720</td>
      <td>Santi Aldama</td>
      <td>Mem</td>
      <td>F-C</td>
      <td>21.93</td>
      <td>26</td>
      <td>24.7</td>
      <td>51.5</td>
      <td>15.3</td>
      <td>6.7</td>
      <td>51</td>
      <td>0.745</td>
      <td>102</td>
      <td>0.578</td>
      <td>98</td>
      <td>0.357</td>
      <td>0.558</td>
      <td>0.587</td>
      <td>10</td>
      <td>5.8</td>
      <td>12.4</td>
      <td>1.4</td>
      <td>7.5</td>
      <td>0.85</td>
      <td>0.92</td>
      <td>0.62</td>
      <td>7</td>
      <td>17.2</td>
    </tr>
    <tr>
      <th>6</th>
      <td>73.518520</td>
      <td>Nickeil Alexander-Walker</td>
      <td>Uta</td>
      <td>G</td>
      <td>24.28</td>
      <td>19</td>
      <td>14.6</td>
      <td>30.4</td>
      <td>19.4</td>
      <td>19.5</td>
      <td>19</td>
      <td>0.737</td>
      <td>43</td>
      <td>0.535</td>
      <td>52</td>
      <td>0.442</td>
      <td>0.605</td>
      <td>0.624</td>
      <td>6.8</td>
      <td>1.6</td>
      <td>6.1</td>
      <td>2</td>
      <td>19.1</td>
      <td>0.63</td>
      <td>0.37</td>
      <td>1.32</td>
      <td>7.6</td>
      <td>10.4</td>
    </tr>
    <tr>
      <th>7</th>
      <td>77.320826</td>
      <td>Grayson Allen</td>
      <td>Mil</td>
      <td>G</td>
      <td>27.18</td>
      <td>24</td>
      <td>27.4</td>
      <td>57.1</td>
      <td>15</td>
      <td>12.4</td>
      <td>57</td>
      <td>0.93</td>
      <td>68</td>
      <td>0.529</td>
      <td>112</td>
      <td>0.42</td>
      <td>0.592</td>
      <td>0.649</td>
      <td>11.1</td>
      <td>3.6</td>
      <td>6.9</td>
      <td>2.6</td>
      <td>13.3</td>
      <td>0.75</td>
      <td>0.21</td>
      <td>1.21</td>
      <td>6.9</td>
      <td>17.3</td>
    </tr>
    <tr>
      <th>8</th>
      <td>82.115039</td>
      <td>Jarrett Allen</td>
      <td>Cle</td>
      <td>C</td>
      <td>24.65</td>
      <td>21</td>
      <td>32.7</td>
      <td>68.2</td>
      <td>17.4</td>
      <td>13.7</td>
      <td>77</td>
      <td>0.74</td>
      <td>196</td>
      <td>0.617</td>
      <td>3</td>
      <td>0</td>
      <td>0.608</td>
      <td>0.642</td>
      <td>14.2</td>
      <td>10.5</td>
      <td>18.8</td>
      <td>1.3</td>
      <td>6.3</td>
      <td>0.67</td>
      <td>1.33</td>
      <td>1.76</td>
      <td>7.1</td>
      <td>26.0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>75.998285</td>
      <td>Jose Alvarado</td>
      <td>Nor</td>
      <td>G</td>
      <td>24.67</td>
      <td>27</td>
      <td>20.8</td>
      <td>43.2</td>
      <td>19.7</td>
      <td>14.6</td>
      <td>39</td>
      <td>0.769</td>
      <td>97</td>
      <td>0.536</td>
      <td>108</td>
      <td>0.38</td>
      <td>0.554</td>
      <td>0.578</td>
      <td>9.5</td>
      <td>2.2</td>
      <td>5.9</td>
      <td>3.2</td>
      <td>21.3</td>
      <td>1.3</td>
      <td>0.15</td>
      <td>1.41</td>
      <td>7.8</td>
      <td>14.9</td>
    </tr>
    <tr>
      <th>10</th>
      <td>75.998285</td>
      <td>Kyle Anderson</td>
      <td>Min</td>
      <td>F-G</td>
      <td>29.23</td>
      <td>22</td>
      <td>23.7</td>
      <td>49.5</td>
      <td>13.3</td>
      <td>20</td>
      <td>44</td>
      <td>0.841</td>
      <td>90</td>
      <td>0.522</td>
      <td>23</td>
      <td>0.435</td>
      <td>0.549</td>
      <td>0.608</td>
      <td>7.3</td>
      <td>4.2</td>
      <td>9.7</td>
      <td>3.4</td>
      <td>18.6</td>
      <td>1.05</td>
      <td>0.82</td>
      <td>1.5</td>
      <td>7.9</td>
      <td>14.9</td>
    </tr>
    <tr>
      <th>11</th>
      <td>94.073016</td>
      <td>Giannis Antetokounmpo</td>
      <td>Mil</td>
      <td>F</td>
      <td>28.02</td>
      <td>23</td>
      <td>33.1</td>
      <td>68.9</td>
      <td>38.9</td>
      <td>12.5</td>
      <td>277</td>
      <td>0.628</td>
      <td>418</td>
      <td>0.579</td>
      <td>74</td>
      <td>0.257</td>
      <td>0.55</td>
      <td>0.582</td>
      <td>31.1</td>
      <td>11.3</td>
      <td>18</td>
      <td>5.3</td>
      <td>32</td>
      <td>0.87</td>
      <td>1</td>
      <td>3.83</td>
      <td>14.9</td>
      <td>47.7</td>
    </tr>
    <tr>
      <th>12</th>
      <td>68.503884</td>
      <td>Thanasis Antetokounmpo</td>
      <td>Mil</td>
      <td>F</td>
      <td>30.41</td>
      <td>13</td>
      <td>3.6</td>
      <td>7.6</td>
      <td>8.9</td>
      <td>50</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>0.5</td>
      <td>1</td>
      <td>0</td>
      <td>0.4</td>
      <td>0.4</td>
      <td>0.3</td>
      <td>0.8</td>
      <td>12.2</td>
      <td>0.2</td>
      <td>7.9</td>
      <td>0</td>
      <td>0.15</td>
      <td>0.38</td>
      <td>4</td>
      <td>1.3</td>
    </tr>
    <tr>
      <th>13</th>
      <td>79.855697</td>
      <td>Cole Anthony</td>
      <td>Orl</td>
      <td>G</td>
      <td>22.58</td>
      <td>11</td>
      <td>27.2</td>
      <td>56.7</td>
      <td>22.1</td>
      <td>10.6</td>
      <td>31</td>
      <td>0.839</td>
      <td>77</td>
      <td>0.468</td>
      <td>45</td>
      <td>0.378</td>
      <td>0.504</td>
      <td>0.549</td>
      <td>13.5</td>
      <td>4.5</td>
      <td>9.5</td>
      <td>3.9</td>
      <td>22.8</td>
      <td>1.09</td>
      <td>0.36</td>
      <td>1.45</td>
      <td>9.1</td>
      <td>21.9</td>
    </tr>
    <tr>
      <th>14</th>
      <td>82.610992</td>
      <td>O.G. Anunoby</td>
      <td>Tor</td>
      <td>F</td>
      <td>25.41</td>
      <td>26</td>
      <td>36.7</td>
      <td>76.4</td>
      <td>22</td>
      <td>13.1</td>
      <td>102</td>
      <td>0.833</td>
      <td>266</td>
      <td>0.541</td>
      <td>121</td>
      <td>0.331</td>
      <td>0.527</td>
      <td>0.571</td>
      <td>19</td>
      <td>5.8</td>
      <td>9</td>
      <td>2.1</td>
      <td>9</td>
      <td>2.38</td>
      <td>0.85</td>
      <td>2.5</td>
      <td>6.7</td>
      <td>26.9</td>
    </tr>
    <tr>
      <th>15</th>
      <td>68.118143</td>
      <td>Ryan Arcidiacono</td>
      <td>Nyk</td>
      <td>G</td>
      <td>28.72</td>
      <td>6</td>
      <td>2.7</td>
      <td>5.5</td>
      <td>10.5</td>
      <td>25</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.3</td>
      <td>6.6</td>
      <td>0.3</td>
      <td>14.8</td>
      <td>0.33</td>
      <td>0</td>
      <td>0.17</td>
      <td>0</td>
      <td>0.6</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-b64d5d53-9083-48bf-8d8f-b169df6352d7')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-b64d5d53-9083-48bf-8d8f-b169df6352d7 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-b64d5d53-9083-48bf-8d8f-b169df6352d7');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
</body>
</html>
